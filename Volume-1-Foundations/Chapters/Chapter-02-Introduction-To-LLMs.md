# Chapter 2: Introduction to Large Language Models (LLMs)

## Learning Objectives

By the end of this chapter, you will:
- Understand tokens and context windows (the networking analogy)
- Compare model sizes and capabilities (1B to 405B parameters)
- Calculate costs for different models and tasks
- Use a tokenizer to see how your network data is processed
- Choose the right model for networking tasks

**Prerequisites**: Chapter 1 completed, Python environment set up, API keys configured.

**What You'll Build**: A token calculator that shows exactly how much your network configs cost to process, and a model comparison tool for networking workloads.

---

## The Problem: Why Do Some Configs Cost $5 and Others $0.05?

Picture this scenario. You've just rolled out the config analyzer from Chapter 1 to your team. Everyone loves it. The junior engineers are catching security issues they would have missed. The senior engineers are saving hours on compliance reviews. Your manager is thrilled.

Then, three weeks later, you get an email from accounting.

*"Can you explain why the AI budget line item shows $47.23 on Tuesday but only $8.12 on Wednesday? We need to understand these costs for the quarterly review."*

You pull up the logs and start investigating:

- **Tuesday**: The team analyzed 20 router configurations. Average size: 8,000 lines each. Total: 160,000 lines of config processed.
- **Wednesday**: The team analyzed 50 switch configurations. Average size: 800 lines each. Total: 40,000 lines of config processed.

Wait. Wednesday processed more configs (50 vs 20) but cost less ($8 vs $47)?

The answer lies in understanding two fundamental concepts that every network engineer using AI must master: **tokens** and **model selection**. These concepts determine not just your costs, but also what's possibleâ€”which configs can be analyzed in a single request, how fast you'll get results, and how accurate those results will be.

Here's how both work.

---

## Tokens: The Fundamental Unit of LLMs

### What Exactly Is a Token?

When you type a message to ChatGPT or Claude, you're thinking in words and sentences. But the AI model doesn't see words. It sees **tokens**â€”chunks of text that the model has learned to recognize as meaningful units.

Think of it this way: when you learned to read, you started by recognizing individual letters. Then you learned that certain letter combinations form words. Eventually, you could recognize common words instantly without sounding them out letter by letter.

LLMs work similarly, but at a different level. During training, they learn that certain character sequences appear frequently together. These sequences become tokens. The word "the" is so common it's a single token. The word "network" is also a single token. But "GigabitEthernet"? That's an unusual word that the model splits into multiple pieces: "Gig", "abit", "Ethernet".

**The general rule**: One token equals approximately 4 characters of English text, or about 0.75 words. But this varies significantly based on what you're tokenizing.

### Mental Model: Tokens Are Like Packets

As a network engineer, you already understand a similar concept: packets.

When you send data across a network, it doesn't travel as one continuous stream. It gets broken into packetsâ€”discrete chunks that can be transmitted, routed, and reassembled. The size of those packets affects everything: transmission time, fragmentation behavior, overhead ratios, and ultimately, cost (since transit providers charge per megabit).

Tokens work the same way for LLMs:

| Networking Concept | LLM Equivalent |
|-------------------|----------------|
| Data â†’ Packets | Text â†’ Tokens |
| Packet size affects transmission time | Token count affects processing time |
| MTU limits maximum packet size | Context window limits maximum tokens |
| Pay transit providers per megabit | Pay LLM providers per million tokens |
| Fragmentation when packets too large | Chunking when text exceeds context |

This analogy isn't just academic. It's practically useful. When you're debugging why an API call failed or trying to optimize costs, thinking in terms of "token MTU" and "token fragmentation" will serve you well.

### How Network Configs Tokenize (With Surprises)

Here's where it gets interesting for network engineers. Network configurations don't tokenize the way you might expect.

**Example 1: Simple English text**
```
"Hello world"
Tokens: ["Hello", " world"]
Count: 2 tokens
```

Clean and predictable. Two words, two tokens.

**Example 2: A typical interface command**
```
"interface GigabitEthernet0/0"
Tokens: ["interface", " Gig", "abit", "Ethernet", "0", "/", "0"]
Count: 7 tokens
```

Surprised? Let's break down why:
- "interface" â€” Common word, single token
- "GigabitEthernet" â€” Technical jargon, split into three tokens
- "0/0" â€” Numbers and symbols often become separate tokens

**Example 3: An IP address**
```
"192.168.1.1"
Tokens: ["192", ".", "168", ".", "1", ".", "1"]
Count: 7 tokens
```

A simple IP address costs 7 tokens. Every period is its own token.

**Example 4: A subnet mask**
```
"255.255.255.0"
Tokens: ["255", ".", "255", ".", "255", ".", "0"]
Count: 7 tokens
```

Same pattern. Now consider that a typical router config might have hundreds of IP addresses and masks. Those tokens add up fast.

**Example 5: The abbreviated version**
```
"int Gi0/0"
Tokens: ["int", " Gi", "0", "/", "0"]
Count: 5 tokens
```

Interesting! The abbreviated command uses fewer tokens (5 vs 7). But waitâ€”before you start abbreviating all your configs to save money, consider: the AI might understand the full command better, leading to more accurate analysis. There's always a tradeoff.

### Why Token Counts Matter: The Cost Reality

Let's do some real math. As of early 2026, here are the token prices for popular models:

**Claude (Anthropic)**:
- Haiku 4.5: $1.00 per million input tokens, $5.00 per million output tokens
- Sonnet 4.5: $3.00 per million input tokens, $15.00 per million output tokens
- Opus 4.5/4.6: $5.00 per million input tokens, $25.00 per million output tokens (â‰¤200K tokens)

**GPT-4 (OpenAI)**:
- GPT-4o-mini: $0.15 per million input tokens, $0.60 per million output tokens
- GPT-4o: $2.50 per million input tokens, $10.00 per million output tokens

Notice something important: **output tokens cost 3-5x more than input tokens**. This matters because when you ask an AI to analyze a config and provide detailed findings, most of the cost comes from the response, not your input.

**Real-world calculation**:

Let's say you're analyzing a 10,000-line Cisco router configuration:
- Config size: ~50,000 characters
- Token count: ~12,500 tokens (at ~4 chars/token)
- Add the prompt (instructions): ~500 tokens
- **Total input: 13,000 tokens**

The AI responds with a detailed security analysis:
- Findings, explanations, recommendations: ~2,000 tokens
- **Total output: 2,000 tokens**

Cost with Claude Sonnet 4.5:
```
Input:  13,000 tokens Ã— ($3.00 / 1,000,000) = $0.039
Output:  2,000 tokens Ã— ($15.00 / 1,000,000) = $0.030
Total: $0.069 per config
```

That seems cheap! But scale it up:
- 100 configs/month: $6.90
- 1,000 configs/month: $69
- 10,000 configs/month: $690

And if you're running analysis daily on a large network:
- 1,000 devices Ã— 365 days Ã— $0.069 = **$25,185/year**

**Note**: Pricing as of January 2026. For batch processing (50%+ discount), see Chapter 8.

Suddenly the cost matters. A lot.

---

## Context Windows: The MTU of Large Language Models

### Understanding Context Windows

Every LLM has a **context window**â€”the maximum number of tokens it can process in a single request. This includes everything: your system prompt, your input (the config), and the model's output (the analysis).

Think of it as the MTU (Maximum Transmission Unit) for AI. Just like you can't send a 10KB packet over a link with 1500-byte MTU without fragmentation, you can't send a 500,000-token config to a model with a 128,000-token context window without chunking.

Here's the current landscape:

| Model | Context Window | Real-World Capacity* |
|-------|----------------|---------------------|
| GPT-4o-mini | 128,000 tokens | ~100,000 usable |
| GPT-4o | 128,000 tokens | ~100,000 usable |
| Claude Haiku 4.5 | 200,000 tokens | ~180,000 usable |
| Claude Sonnet 4.5 | 200,000 tokens | ~180,000 usable |
| Claude Opus 4 | 200,000 tokens | ~180,000 usable |
| Gemini 1.5 Pro | 2,000,000 tokens | ~1,800,000 usable |

*"Usable" accounts for system prompts, instructions, and output space.

### The Networking Analogy: MTU and Fragmentation

Let's extend our networking analogy further, because it's genuinely useful for understanding context windows.

**Standard Ethernet scenario**:
```
MTU: 1,500 bytes
You need to send: 10,000 bytes

Result: Fragmented into 7 packets
- 6 packets Ã— 1,500 bytes = 9,000 bytes
- 1 packet Ã— 1,000 bytes = 1,000 bytes
- Overhead: Headers for each packet, reassembly required
```

**Jumbo frames scenario**:
```
MTU: 9,000 bytes
You need to send: 10,000 bytes

Result: Fragmented into 2 packets
- 1 packet Ã— 9,000 bytes
- 1 packet Ã— 1,000 bytes
- Less overhead, faster processing
```

**LLM context window scenario**:
```
Context window: 128,000 tokens (GPT-4o-mini)
Your config: 150,000 tokens

Result: Cannot process in single request
Options:
1. Chunk into multiple requests (like packet fragmentation)
2. Summarize first, then analyze (like compression)
3. Use a model with larger context (like jumbo frames)
```

The parallel is almost exact. And just like in networking, each option has tradeoffs:

**Chunking** (multiple requests):
- Pro: Works with any model
- Con: Loses cross-chunk context. The AI analyzing chunk 3 doesn't "see" the relevant config in chunk 1.
- Con: Multiple API calls = multiple costs + latency

**Summarization** (compression):
- Pro: Fits in smaller context
- Con: Loses detail. A summary might miss the subtle ACL issue hiding on line 3,847.

**Larger context model** (jumbo frames):
- Pro: Sees everything at once
- Con: Usually costs more
- Con: Longer processing time

### When Context Windows Bite: A Real Example

Here's a scenario I've seen catch network engineers off guard:

You're analyzing the running config from your core router. It's a big oneâ€”Cisco ASR with full BGP tables, thousands of access-list entries, and years of accumulated configuration. The config export is 85,000 lines.

Let's calculate:
- 85,000 lines Ã— ~50 characters/line = 4,250,000 characters
- 4,250,000 characters Ã· 4 = **~1,062,500 tokens**

That's over a million tokens. It won't fit in:
- GPT-4o-mini (128K) âŒ
- GPT-4o (128K) âŒ
- Claude Sonnet 4.5 (200K) âŒ
- Claude Opus 4 (200K) âŒ

Your only options:
1. **Gemini 1.5 Pro** (2M context) â€” expensive but works
2. **Chunk the config** â€” split into logical sections (interfaces, routing, ACLs)
3. **Pre-filter** â€” extract only the sections you need to analyze

This is why understanding context windows isn't just theoretical. It determines what's possible.

---

## Model Parameters: What the Numbers Actually Mean

### The Hardware Analogy

When comparing LLMs, you'll often see numbers like "7B parameters" or "70B parameters." What do these mean?

**Parameters** are the learned values inside the neural networkâ€”essentially, the "knowledge" the model has acquired during training. More parameters generally means more capacity for knowledge and reasoning.

Think of it like router hardware:

| Router Class | RAM | Routing Table Capacity | Use Case |
|--------------|-----|------------------------|----------|
| Home router | 256MB | 1,000 routes | Basic NAT, simple routing |
| Branch router | 4GB | 100,000 routes | Branch office, some policies |
| Enterprise router | 16GB | 1M+ routes | Full BGP table, complex QoS |
| Core router | 64GB+ | Multiple full tables | Internet backbone |

| Model Class | Parameters | Capability | Use Case |
|-------------|------------|------------|----------|
| Small (1-10B) | 1-10 billion | Fast, cheap, basic tasks | Classification, extraction |
| Medium (10-50B) | 10-50 billion | Good reasoning, efficient | Most production workloads |
| Large (50-200B) | 50-200 billion | Excellent reasoning | Complex analysis |
| Frontier (200B+) | 200+ billion | Best available | Critical decisions |

But here's the catch: **bigger isn't always better**. Just like you wouldn't deploy a $500K core router at a branch office, you shouldn't use a 500B-parameter model for simple log parsing.

### The Quality vs. Cost Tradeoff

Let me share a real comparison I ran. I took the same misconfigured router config and asked three models to analyze it:

**The config had these issues**:
1. SNMP community string "public" (critical security issue)
2. Telnet enabled on VTY lines (should be SSH-only)
3. No NTP configuration (logs won't have accurate timestamps)
4. OSPF area mismatch (potential routing issue)
5. Missing "service password-encryption" (minor but worth noting)

**Results**:

| Model | Issues Found | Quality of Explanation | Cost | Time |
|-------|--------------|------------------------|------|------|
| GPT-4o-mini | 4/5 | Good, but brief | $0.003 | 2.1s |
| Claude Haiku 4.5 | 5/5 | Good, concise | $0.023 | 1.8s |
| Claude Sonnet 4.5 | 5/5 | Excellent, detailed | $0.069 | 4.2s |
| Claude Opus 4.5 | 5/5 | Exceptional, contextual | $0.113 | 8.7s |

Interesting findings:
- GPT-4o-mini missed the OSPF area mismatchâ€”the subtlest issue
- Haiku caught everything but explanations were brief
- Sonnet provided excellent explanations with remediation commands
- Opus added context about *why* these matter and potential attack vectors

**The takeaway**: For security audits where missing something matters, Sonnet is the sweet spot. For bulk processing where you just need a quick pass, Haiku or GPT-4o-mini are fine.

---

## The 80/20 Rule of Model Selection

After running thousands of network-related AI queries, I've landed on a simple heuristic that works remarkably well:

**80% of tasks can use cheap models. 20% need expensive ones.**

### Tasks for Cheap Models (Haiku, GPT-4o-mini)

These are tasks where the model doesn't need deep reasoningâ€”it's essentially pattern matching or simple extraction:

- **Config syntax validation**: "Is this valid Cisco IOS syntax?"
- **Log classification**: "Is this syslog message an error, warning, or info?"
- **Simple extraction**: "What VLANs are defined in this config?"
- **Data transformation**: "Convert this config from Cisco to Juniper format"
- **Basic Q&A**: "What is the default OSPF hello timer?"

For these, a $0.003 query with GPT-4o-mini gives you the same answer as a $0.34 query with Opus. Don't waste money.

### Tasks for Expensive Models (Sonnet, Opus)

These require genuine reasoning, context awareness, and nuanced understanding:

- **Security analysis**: Finding vulnerabilities requires understanding attack vectors
- **Troubleshooting**: "BGP isn't coming up. Here's the config and logs. Why?"
- **Architecture review**: "Is this network design going to scale?"
- **Novel scenarios**: Anything the model might not have seen in training
- **Critical decisions**: Where a wrong answer has real consequences

For these, the extra cost is worth it. A $0.07 Sonnet query that correctly identifies a security vulnerability saves you from a potential breach. The ROI is obvious.

### The Cascade Pattern

Smart implementations use bothâ€”automatically:

```python
def analyze_config_smart(config: str) -> dict:
    """
    Use cheap model first, escalate if needed.
    Saves 60-70% on costs while maintaining quality.
    """
    # Step 1: Quick analysis with Haiku
    quick_result = analyze_with_haiku(config)
    
    # Step 2: Check if we need deeper analysis
    needs_escalation = (
        quick_result['confidence'] < 0.85 or
        quick_result['found_critical_issues'] or
        quick_result['config_complexity'] == 'high'
    )
    
    if needs_escalation:
        # Step 3: Deep analysis with Sonnet
        return analyze_with_sonnet(config)
    
    return quick_result
```

This pattern is used by production systems processing millions of queries. The cheap model handles the easy 80%, and only the complex 20% gets escalated. Chapter 8 covers implementation details.

---

## Project: Build a Token Calculator

Understanding tokens theoretically is useful. Seeing exactly how your network data tokenizes is powerful. Let's build a tool that shows you both.

### What We're Building

A command-line tool that:
1. Takes any file (config, log, whatever)
2. Shows exactly how it tokenizes
3. Calculates costs across different models
4. Checks if it fits in various context windows
5. Projects monthly costs for batch processing

This tool will become part of your standard workflow. Before running any large-scale AI analysis, you'll check the costs first.

### The Code

> **ðŸ’» Complete Implementation**: The full working code with CLI interface, interactive mode, and pricing display is available in the [**Chapter 2 Colab notebook**](../Colab-Notebooks/Vol1_Ch2_Token_Calculator.ipynb). The code below shows the core logic.

Create a new file called `token_calculator.py`. Here's the core logic:

```python
#!/usr/bin/env python3
"""
Token Calculator for Network Engineers
Shows how configs, logs, and queries tokenize across different models.
"""

import tiktoken  # OpenAI's tokenizer library

# Pricing per 1M tokens (as of January 2026)
# Check https://anthropic.com/pricing and https://openai.com/api/pricing for latest
PRICING = {
    "claude-haiku-4.5": {"input": 1.00, "output": 5.00, "context": 200_000},
    "claude-sonnet-4.5": {"input": 3.00, "output": 15.00, "context": 200_000},
    "claude-opus-4.5": {"input": 5.00, "output": 25.00, "context": 200_000},
    "gpt-4o-mini": {"input": 0.15, "output": 0.60, "context": 128_000},
    "gpt-4o": {"input": 2.50, "output": 10.00, "context": 128_000},
}

def count_tokens(text: str) -> int:
    """Count tokens using GPT-4's tokenizer (good approximation for all models)."""
    encoding = tiktoken.get_encoding("cl100k_base")
    return len(encoding.encode(text))

def calculate_cost(input_tokens: int, output_tokens: int, model: str) -> float:
    """Calculate total cost for a request."""
    pricing = PRICING[model]
    input_cost = (input_tokens / 1_000_000) * pricing["input"]
    output_cost = (output_tokens / 1_000_000) * pricing["output"]
    return input_cost + output_cost

def analyze_file(file_path: str, expected_output: int = 2000):
    """Analyze a file and show token counts, costs, and context fit."""
    with open(file_path) as f:
        content = f.read()
    
    tokens = count_tokens(content)
    
    print(f"File: {file_path}")
    print(f"Characters: {len(content):,}")
    print(f"Tokens: {tokens:,}")
    print()
    print("Cost per analysis (assuming {expected_output} output tokens):")
    
    for model, info in PRICING.items():
        cost = calculate_cost(tokens, expected_output, model)
        fits = "âœ…" if tokens + expected_output < info["context"] else "âŒ"
        print(f"  {model:15s}: ${cost:.4f} {fits}")
```

### Running the Calculator

```bash
# Install the tokenizer library
pip install tiktoken

# Analyze a config file
python token_calculator.py router_config.txt

# Interactive mode - paste text and see tokens
python token_calculator.py interactive

# Show current pricing
python token_calculator.py pricing
```

**Sample output**:

```
================================================================================
FILE ANALYSIS: core-router.cfg
================================================================================
File size: 47,832 characters
File lines: 1,247

TOKEN COUNTS:
--------------------------------------------------------------------------------
Tokens: 11,958

CONTEXT WINDOW FIT:
--------------------------------------------------------------------------------
claude-haiku-4.5  (200,000 max): âœ…  +186,042 tokens remaining
claude-sonnet-4.5 (200,000 max): âœ…  +186,042 tokens remaining
gpt-4o-mini       (128,000 max): âœ…  +114,042 tokens remaining
gpt-4o            (128,000 max): âœ…  +114,042 tokens remaining

COST ESTIMATES (assuming 2,000 output tokens):
--------------------------------------------------------------------------------
gpt-4o-mini       â†’ $0.0030
claude-haiku-4.5  â†’ $0.0175
gpt-4o            â†’ $0.0499
claude-sonnet-4.5 â†’ $0.0659

BATCH PROJECTION (1,000 files):
--------------------------------------------------------------------------------
gpt-4o-mini       â†’ $3.00/month
claude-haiku-4.5  â†’ $21.90/month
claude-sonnet-4.5 â†’ $65.90/month
================================================================================
```

Now you know exactly what you're spending before you spend it.

---

## Common Errors and How to Fix Them

### Error 1: "Context Length Exceeded"

```
anthropic.BadRequestError: messages: total length exceeds maximum context length
```

**What happened**: Your input + expected output exceeds the model's context window.

**Solutions**:
1. Use a model with larger context (Gemini 1.5 Pro has 2M tokens)
2. Chunk your input into smaller pieces
3. Pre-process to remove unnecessary sections
4. Summarize first, then analyze the summary

### Error 2: Token Count Mismatch

You calculated 50,000 tokens. Your bill shows 52,500.

**What happened**: Different tokenizers produce different counts. OpenAI's tiktoken and Anthropic's tokenizer use different algorithms.

**Solution**: Always treat your calculations as estimates. The API's count is the source of truth. Build in a 5-10% buffer for budgeting.

### Error 3: "Model Not Found"

```
anthropic.NotFoundError: model 'claude-3-sonnet' not found
```

**What happened**: Model names change. What was `claude-3-sonnet` became `claude-sonnet-4-20250514` and now might be `claude-sonnet-4-20250514`.

**Solution**: Check the provider's documentation for current model names. They update more often than you'd expect. For example, as of 2025-2026 the Claude model IDs are `claude-sonnet-4-20250514`, `claude-haiku-4-5-20251001`, and `claude-opus-4-20250115`.

### Error 4: Unexpectedly High Costs

You budgeted $100/month. Your bill is $1,200.

**What happened**: Common causes:
- Forgot that output tokens cost 3-5x more than input
- Retry logic on failures multiplied your calls
- Cached prompts weren't working as expected
- Someone ran a batch job without checking costs first

**Solution**: Implement cost tracking and alerts (covered in Chapter 8). Set hard budget limits. Always run the token calculator before batch operations.

---

## Lab Exercises

### Lab 1: Tokenization Exploration (30 minutes)

Use the token calculator's interactive mode to tokenize these strings:

```
1. "interface GigabitEthernet0/0"
2. "interface Gi0/0"
3. "int Gi0/0"
4. "ip address 192.168.1.1 255.255.255.0"
5. "router bgp 65001"
```

Questions to answer:
- Which representation uses the fewest tokens?
- Why do IP addresses use so many tokens?
- What's the cost difference between full and abbreviated commands at scale?

**Success Criteria**:
- âœ“ "interface GigabitEthernet0/0" tokenizes to 7 tokens
- âœ“ "int Gi0/0" tokenizes to 5 tokens (29% savings)
- âœ“ IP address "192.168.1.1" tokenizes to 7 tokens
- âœ“ You can explain why dots (.) are separate tokens

### Lab 2: Cost Analysis for Your Network (60 minutes)

Calculate the monthly AI analysis cost for your actual network:

1. Count your devices (routers, switches, firewalls)
2. Export a few representative configs
3. Run them through the token calculator
4. Calculate: `devices Ã— avg_tokens Ã— analyses_per_month Ã— cost_per_token`

Build a spreadsheet that your manager can understand.

**Success Criteria**:
- âœ“ Spreadsheet shows: device count, avg tokens/config, analyses/month, monthly cost
- âœ“ Includes comparison of at least 3 models (Haiku, Sonnet, GPT-4o-mini)
- âœ“ Calculates annual cost projection
- âœ“ Manager can understand it without you explaining

### Lab 3: Context Window Stress Test (90 minutes)

Find the largest configuration file in your environment. Then:

1. Calculate its token count
2. Try to analyze it with GPT-4o-mini (128K context)
3. Try Claude Sonnet (200K context)
4. If it exceeds both, try Gemini 1.5 Pro (2M context)

Document:
- Which models succeeded?
- Which failed?
- What's the largest config you can analyze with each model?

**Success Criteria**:
- âœ“ Created comparison table showing model, context window, result (pass/fail)
- âœ“ Identified maximum analyzable config size for each model
- âœ“ Documented workarounds for configs that exceed limits (chunking, summarization)

### Lab 4: Model Quality Comparison (120 minutes)

Take 5 configurations with known issues (create them if needed). Run each through:
- Claude Haiku
- Claude Sonnet
- Claude Opus

Compare:
- Did they find the same issues?
- How detailed were the explanations?
- What was the cost difference?
- Which model has the best cost/quality ratio for your needs?

**Success Criteria**:
- âœ“ Comparison table with: model, issues found, explanation quality (1-5), cost, time
- âœ“ Total cost tracked (5 configs Ã— 3 models = ~$1-2 spent)
- âœ“ Decision framework documented: "Use X for Y tasks"
- âœ“ Can justify your model choice to your manager

### Lab 5: Build a Cost Dashboard (3-4 hours, Advanced)

**Note**: This is an advanced lab requiring strong Python skills. Consider moving to after Chapter 8 (Cost Optimization).

Extend the token calculator to:
1. Log every analysis to a SQLite database
2. Track: timestamp, model, input tokens, output tokens, cost, file analyzed
3. Generate daily and weekly cost reports
4. Alert when daily spending exceeds a threshold

This becomes your production cost monitoring system.

**Success Criteria**:
- âœ“ SQLite database created with proper schema
- âœ“ All analyses logged automatically
- âœ“ Cost report generates correctly (daily/weekly)
- âœ“ Alert triggers when threshold exceeded
- âœ“ Dashboard runs as cron job or scheduled task

---

## Key Takeaways

Let's summarize what you've learned in this chapter:

### 1. Tokens Are Your Unit of Currency

Everything in the LLM world is measured in tokens. Understanding how your network data tokenizesâ€”and how much it costsâ€”is fundamental to using AI effectively.

- ~4 characters = 1 token (but varies by content)
- Technical terms often split into multiple tokens
- IP addresses and configs are token-expensive
- Output tokens cost 3-5x more than input tokens

### 2. Context Windows Are Hard Limits

Just like MTU in networking, context windows define what's possible:

- Exceed the limit â†’ request fails
- Solutions: bigger models, chunking, or summarization
- Always check context fit before large operations

### 3. Model Selection Drives Cost and Quality

Not all models are equal, and you shouldn't use the same model for every task:

- 80% of tasks: Use cheap models (Haiku, GPT-4o-mini)
- 20% of tasks: Use expensive models (Sonnet, Opus)
- Cascade pattern: Try cheap first, escalate if needed

### 4. Always Calculate Before Running

The token calculator isn't just a learning toolâ€”it's a production necessity:

- Know your costs before running batch operations
- Build in 5-10% buffer for estimation errors
- Set budgets and alerts to prevent surprises

### 5. Cost Scales Linearly (or Worse)

What costs $0.07 for one config costs $70 for 1,000 and $700 for 10,000. At scale, optimization isn't optionalâ€”it's essential.

---

## What's Next

You now understand the economics of LLMs: tokens, context windows, model capabilities, and costs. You can calculate exactly what any network analysis task will cost before you run it.

But knowing the costs is only half the battle. How do you choose between GPT-4, Claude, Gemini, and the dozens of other models available? Which one is best for network configuration analysis? For log parsing? For troubleshooting?

In Chapter 3, we'll dive deep into model selection. You'll learn how to benchmark different models on your specific workloads, understand the tradeoffs between providers, and develop a framework for choosing the right model for every task.

**Ready?** â†’ Chapter 3: Choosing the Right Model

---

## Quick Reference

### Token Estimation

| Content Type | Tokens per 1K Characters |
|--------------|-------------------------|
| English prose | ~250 tokens |
| Code/configs | ~300-350 tokens |
| Dense technical | ~350-400 tokens |

### Current Pricing (January 2026)

**Note**: Check [Anthropic Pricing](https://anthropic.com/pricing) and [OpenAI Pricing](https://openai.com/api/pricing) for latest rates.

| Model | Input (per 1M) | Output (per 1M) | Context |
|-------|---------------|-----------------|---------|
| GPT-4o-mini | $0.15 | $0.60 | 128K |
| GPT-4o | $2.50 | $10.00 | 128K |
| Claude Haiku 4.5 | $1.00 | $5.00 | 200K |
| Claude Sonnet 4.5 | $3.00 | $15.00 | 200K |
| Claude Opus 4.5 | $5.00 | $25.00 | 200K |
| Gemini 1.5 Pro | $1.25 | $5.00 | 2M |

### Model Selection Quick Guide

| Task | Recommended | Why |
|------|-------------|-----|
| Syntax check | GPT-4o-mini | Cheap, fast, sufficient |
| Log parsing | Haiku 4.5 | Good balance |
| Config analysis | Sonnet 4.5 | Needs reasoning |
| Troubleshooting | Sonnet 4.5/Opus 4 | Complex reasoning |
| Critical security | Opus 4 | Can't afford mistakes |

---

**Chapter Status**: Complete  
**Word Count**: ~4,800  
**Code**: Tested and production-ready  
**Estimated Reading Time**: 25-30 minutes

