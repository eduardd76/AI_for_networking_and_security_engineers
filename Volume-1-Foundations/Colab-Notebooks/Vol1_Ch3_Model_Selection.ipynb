{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Volume 1, Chapter 3: Choosing the Right Model\n",
    "\n",
    "**Compare Claude, GPT, and Gemini for Network Tasks**\n",
    "\n",
    "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/eduardd76/AI_for_networking_and_security_engineers/blob/master/Volume-1-Foundations/Colab-Notebooks/Vol1_Ch3_Model_Selection.ipynb)\n",
    "\n",
    "---\n",
    "\n",
    "**What you'll learn:**\n",
    "- üèéÔ∏è Compare model speed and quality\n",
    "- üíµ Understand cost/performance tradeoffs\n",
    "- üéØ Match models to networking tasks\n",
    "- üìä Benchmark on real network data\n",
    "\n",
    "**Time:** ~15 minutes | **Cost:** ~$0.10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üîß Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -q anthropic openai\n",
    "\n",
    "import os\n",
    "import time\n",
    "from getpass import getpass\n",
    "\n",
    "# Anthropic API key\n",
    "try:\n",
    "    from google.colab import userdata\n",
    "    os.environ['ANTHROPIC_API_KEY'] = userdata.get('ANTHROPIC_API_KEY')\n",
    "    print(\"‚úì Anthropic key loaded\")\n",
    "except:\n",
    "    if 'ANTHROPIC_API_KEY' not in os.environ:\n",
    "        os.environ['ANTHROPIC_API_KEY'] = getpass('Anthropic API key: ')\n",
    "\n",
    "# OpenAI API key (optional)\n",
    "try:\n",
    "    os.environ['OPENAI_API_KEY'] = userdata.get('OPENAI_API_KEY')\n",
    "    print(\"‚úì OpenAI key loaded\")\n",
    "except:\n",
    "    print(\"‚ÑπÔ∏è OpenAI key not set (optional)\")\n",
    "\n",
    "from anthropic import Anthropic\n",
    "anthropic_client = Anthropic()\n",
    "print(\"‚úì Ready!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## üìä Model Comparison Chart\n",
    "\n",
    "| Model | Speed | Quality | Cost | Best For |\n",
    "|-------|-------|---------|------|----------|\n",
    "| **Claude 3.5 Haiku** | ‚ö°‚ö°‚ö° | ‚òÖ‚òÖ‚òÖ‚òÜ | $0.25/1M | Log parsing, simple tasks |\n",
    "| **Claude 3.5 Sonnet** | ‚ö°‚ö° | ‚òÖ‚òÖ‚òÖ‚òÖ | $3/1M | Config analysis, troubleshooting |\n",
    "| **Claude 3 Opus** | ‚ö° | ‚òÖ‚òÖ‚òÖ‚òÖ‚òÖ | $15/1M | Complex reasoning, design |\n",
    "| **GPT-4o** | ‚ö°‚ö° | ‚òÖ‚òÖ‚òÖ‚òÖ | $2.5/1M | General tasks |\n",
    "| **GPT-4o-mini** | ‚ö°‚ö°‚ö° | ‚òÖ‚òÖ‚òÖ‚òÜ | $0.15/1M | High volume, simple tasks |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## üèéÔ∏è Example 1: Speed Comparison (Haiku vs Sonnet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def benchmark_model(model_name, prompt, runs=3):\n",
    "    \"\"\"Benchmark a model's speed.\"\"\"\n",
    "    times = []\n",
    "    response_text = \"\"\n",
    "    \n",
    "    for _ in range(runs):\n",
    "        start = time.time()\n",
    "        response = anthropic_client.messages.create(\n",
    "            model=model_name,\n",
    "            max_tokens=300,\n",
    "            temperature=0,\n",
    "            messages=[{\"role\": \"user\", \"content\": prompt}]\n",
    "        )\n",
    "        elapsed = time.time() - start\n",
    "        times.append(elapsed)\n",
    "        response_text = response.content[0].text\n",
    "    \n",
    "    return {\n",
    "        \"model\": model_name,\n",
    "        \"avg_time\": sum(times) / len(times),\n",
    "        \"min_time\": min(times),\n",
    "        \"response_preview\": response_text[:150] + \"...\"\n",
    "    }\n",
    "\n",
    "# Simple task - log classification\n",
    "simple_prompt = \"\"\"Classify this log severity (INFO/WARNING/ERROR/CRITICAL):\n",
    "%OSPF-5-ADJCHG: Process 1, Nbr 10.1.1.2 on Vlan100 from FULL to DOWN\n",
    "Return only the classification.\"\"\"\n",
    "\n",
    "print(\"üèéÔ∏è SPEED BENCHMARK: Simple Task (Log Classification)\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "models = [\n",
    "    \"claude-haiku-4-5-20251001\",\n",
    "    \"claude-sonnet-4-20250514\"\n",
    "]\n",
    "\n",
    "for model in models:\n",
    "    result = benchmark_model(model, simple_prompt)\n",
    "    print(f\"\\n{model}:\")\n",
    "    print(f\"  Avg time: {result['avg_time']:.2f}s\")\n",
    "    print(f\"  Response: {result['response_preview']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## üß† Example 2: Quality Comparison (Complex Task)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Complex task - troubleshooting\n",
    "complex_prompt = \"\"\"Two routers can't establish BGP. Diagnose the issue:\n",
    "\n",
    "R1 config:\n",
    "router bgp 65001\n",
    " neighbor 10.1.1.2 remote-as 65002\n",
    " neighbor 10.1.1.2 update-source Loopback0\n",
    "\n",
    "interface Loopback0\n",
    " ip address 1.1.1.1 255.255.255.255\n",
    "\n",
    "R2 config:\n",
    "router bgp 65002\n",
    " neighbor 10.1.1.1 remote-as 65001\n",
    "\n",
    "R2 show ip bgp summary:\n",
    "Neighbor        State/PfxRcd\n",
    "10.1.1.1        Idle\n",
    "\n",
    "What's wrong? Provide the fix.\"\"\"\n",
    "\n",
    "print(\"üß† QUALITY COMPARISON: Complex Troubleshooting\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "for model in models:\n",
    "    start = time.time()\n",
    "    response = anthropic_client.messages.create(\n",
    "        model=model,\n",
    "        max_tokens=500,\n",
    "        temperature=0,\n",
    "        messages=[{\"role\": \"user\", \"content\": complex_prompt}]\n",
    "    )\n",
    "    elapsed = time.time() - start\n",
    "    \n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(f\"MODEL: {model}\")\n",
    "    print(f\"Time: {elapsed:.2f}s\")\n",
    "    print(f\"{'='*60}\")\n",
    "    print(response.content[0].text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## üíµ Example 3: Cost Calculator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PRICING = {\n",
    "    \"claude-haiku-4-5-20251001\": {\"input\": 0.25, \"output\": 1.25, \"name\": \"Haiku\"},\n",
    "    \"claude-sonnet-4-20250514\": {\"input\": 3.00, \"output\": 15.00, \"name\": \"Sonnet\"},\n",
    "    \"claude-opus-4-20250115\": {\"input\": 15.00, \"output\": 75.00, \"name\": \"Opus\"},\n",
    "    \"gpt-4o\": {\"input\": 2.50, \"output\": 10.00, \"name\": \"GPT-4o\"},\n",
    "    \"gpt-4o-mini\": {\"input\": 0.15, \"output\": 0.60, \"name\": \"GPT-4o-mini\"},\n",
    "}\n",
    "\n",
    "def monthly_cost(calls_per_day, input_tokens, output_tokens, model):\n",
    "    \"\"\"Calculate monthly cost.\"\"\"\n",
    "    p = PRICING[model]\n",
    "    daily_input_cost = (input_tokens * calls_per_day / 1_000_000) * p[\"input\"]\n",
    "    daily_output_cost = (output_tokens * calls_per_day / 1_000_000) * p[\"output\"]\n",
    "    return (daily_input_cost + daily_output_cost) * 30\n",
    "\n",
    "# Scenario: NOC team analyzing 500 logs per day\n",
    "print(\"üíµ MONTHLY COST COMPARISON\")\n",
    "print(\"=\" * 60)\n",
    "print(\"Scenario: Analyze 500 log entries per day\")\n",
    "print(\"         ~200 input tokens, ~100 output tokens each\")\n",
    "print(\"=\" * 60 + \"\\n\")\n",
    "\n",
    "for model_key, model_info in PRICING.items():\n",
    "    cost = monthly_cost(\n",
    "        calls_per_day=500,\n",
    "        input_tokens=200,\n",
    "        output_tokens=100,\n",
    "        model=model_key\n",
    "    )\n",
    "    print(f\"{model_info['name']:15} ${cost:>8.2f}/month\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## üéØ Example 4: Model Selection Guide"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def recommend_model(task_type, volume, budget):\n",
    "    \"\"\"Recommend best model based on requirements.\"\"\"\n",
    "    \n",
    "    recommendations = {\n",
    "        (\"simple\", \"high\", \"low\"): \"claude-haiku-4-5-20251001\",\n",
    "        (\"simple\", \"high\", \"medium\"): \"claude-haiku-4-5-20251001\",\n",
    "        (\"simple\", \"low\", \"low\"): \"claude-haiku-4-5-20251001\",\n",
    "        (\"medium\", \"high\", \"low\"): \"claude-haiku-4-5-20251001\",\n",
    "        (\"medium\", \"high\", \"medium\"): \"claude-sonnet-4-20250514\",\n",
    "        (\"medium\", \"low\", \"medium\"): \"claude-sonnet-4-20250514\",\n",
    "        (\"complex\", \"low\", \"high\"): \"claude-opus-4-20250115\",\n",
    "        (\"complex\", \"low\", \"medium\"): \"claude-sonnet-4-20250514\",\n",
    "        (\"complex\", \"high\", \"high\"): \"claude-sonnet-4-20250514\",\n",
    "    }\n",
    "    \n",
    "    key = (task_type, volume, budget)\n",
    "    return recommendations.get(key, \"claude-sonnet-4-20250514\")\n",
    "\n",
    "# Task type mapping\n",
    "TASK_EXAMPLES = {\n",
    "    \"simple\": [\"Log classification\", \"Data extraction\", \"Format conversion\"],\n",
    "    \"medium\": [\"Config analysis\", \"Documentation\", \"Compliance checking\"],\n",
    "    \"complex\": [\"Troubleshooting\", \"Design review\", \"Root cause analysis\"]\n",
    "}\n",
    "\n",
    "print(\"üéØ MODEL SELECTION GUIDE\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "scenarios = [\n",
    "    {\"task\": \"Log classification\", \"type\": \"simple\", \"volume\": \"high\", \"budget\": \"low\"},\n",
    "    {\"task\": \"Config security audit\", \"type\": \"medium\", \"volume\": \"low\", \"budget\": \"medium\"},\n",
    "    {\"task\": \"BGP troubleshooting\", \"type\": \"complex\", \"volume\": \"low\", \"budget\": \"medium\"},\n",
    "    {\"task\": \"Network design review\", \"type\": \"complex\", \"volume\": \"low\", \"budget\": \"high\"},\n",
    "]\n",
    "\n",
    "for s in scenarios:\n",
    "    model = recommend_model(s[\"type\"], s[\"volume\"], s[\"budget\"])\n",
    "    print(f\"\\nüìå {s['task']}\")\n",
    "    print(f\"   Complexity: {s['type']} | Volume: {s['volume']} | Budget: {s['budget']}\")\n",
    "    print(f\"   ‚Üí Recommended: {PRICING[model]['name']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## üî¨ Example 5: Real-World Benchmark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Benchmark on network-specific tasks\n",
    "tasks = [\n",
    "    {\n",
    "        \"name\": \"Log Classification\",\n",
    "        \"prompt\": \"Classify: %LINK-3-UPDOWN: Interface Gi0/1, changed state to down. Return: INFO/WARNING/ERROR/CRITICAL\",\n",
    "        \"expected\": \"ERROR\"\n",
    "    },\n",
    "    {\n",
    "        \"name\": \"Config Extraction\", \n",
    "        \"prompt\": \"Extract IP address from: interface Gi0/0\\n ip address 10.1.1.1 255.255.255.0. Return only the IP.\",\n",
    "        \"expected\": \"10.1.1.1\"\n",
    "    },\n",
    "    {\n",
    "        \"name\": \"Subnet Calculation\",\n",
    "        \"prompt\": \"How many usable hosts in a /26 network? Return only the number.\",\n",
    "        \"expected\": \"62\"\n",
    "    }\n",
    "]\n",
    "\n",
    "print(\"üî¨ ACCURACY BENCHMARK\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "for model in models:\n",
    "    print(f\"\\n{model}:\")\n",
    "    correct = 0\n",
    "    \n",
    "    for task in tasks:\n",
    "        response = anthropic_client.messages.create(\n",
    "            model=model,\n",
    "            max_tokens=50,\n",
    "            temperature=0,\n",
    "            messages=[{\"role\": \"user\", \"content\": task[\"prompt\"]}]\n",
    "        )\n",
    "        answer = response.content[0].text.strip()\n",
    "        is_correct = task[\"expected\"].lower() in answer.lower()\n",
    "        correct += is_correct\n",
    "        status = \"‚úÖ\" if is_correct else \"‚ùå\"\n",
    "        print(f\"  {status} {task['name']}: {answer[:30]}\")\n",
    "    \n",
    "    print(f\"  Score: {correct}/{len(tasks)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## üéØ Key Takeaways\n",
    "\n",
    "| Use Case | Recommended Model | Why |\n",
    "|----------|-------------------|-----|\n",
    "| High-volume log parsing | **Haiku** | Fast, cheap, accurate enough |\n",
    "| Config analysis | **Sonnet** | Good balance of quality/cost |\n",
    "| Complex troubleshooting | **Sonnet** or **Opus** | Needs reasoning ability |\n",
    "| Network design | **Opus** | Highest quality matters |\n",
    "\n",
    "**Decision flow:**\n",
    "1. Start with Haiku\n",
    "2. If quality insufficient ‚Üí upgrade to Sonnet\n",
    "3. For critical/complex tasks ‚Üí consider Opus\n",
    "\n",
    "---\n",
    "\n",
    "## üìö Next Steps\n",
    "\n",
    "‚û°Ô∏è [Chapter 4: API Basics](./Vol1_Ch4_API_Basics.ipynb)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
