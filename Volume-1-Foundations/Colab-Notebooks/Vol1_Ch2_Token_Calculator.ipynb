{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "name": "Vol1_Ch2_Token_Calculator.ipynb"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Volume 1, Chapter 2: Introduction to LLMs\n",
        "\n",
        "**Token Calculator & Model Cost Comparison**\n",
        "\n",
        "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/eduardd76/AI_for_networking_and_security_engineers/blob/main/Volume-1-Foundations/Colab-Notebooks/Vol1_Ch2_Token_Calculator.ipynb)\n",
        "\n",
        "## What You'll Build\n",
        "\n",
        "By the end of this notebook, you'll have:\n",
        "- A working token calculator for network configs\n",
        "- Cost comparison tool across all major models\n",
        "- Understanding of how your network data tokenizes\n",
        "- Batch processing cost projections\n",
        "\n",
        "## Prerequisites\n",
        "\n",
        "- Completed Chapter 1\n",
        "- Python basics\n",
        "- No API key needed for token counting (only for actual API calls)\n",
        "\n",
        "**Estimated Time**: 30-45 minutes  \n",
        "**Cost**: Free (token counting only, no API calls required)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "## ðŸ”§ Setup: Install Dependencies\n",
        "\n",
        "We'll use `tiktoken` - OpenAI's tokenizer library. It's a good approximation for all models (Claude, GPT, etc.)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Install tiktoken\n",
        "!pip install -q tiktoken\n",
        "\n",
        "print(\"âœ“ tiktoken installed successfully!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "## ðŸ“Š Current Model Pricing (January 2026)\n",
        "\n",
        "Let's define the pricing for all major models. This will be used throughout the notebook."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Pricing per 1M tokens (as of January 2026)\n",
        "# Check https://anthropic.com/pricing and https://openai.com/api/pricing for latest\n",
        "PRICING = {\n",
        "    \"claude-haiku-4.5\": {\n",
        "        \"input\": 1.00,\n",
        "        \"output\": 5.00,\n",
        "        \"context\": 200_000,\n",
        "        \"name\": \"Claude Haiku 4.5\"\n",
        "    },\n",
        "    \"claude-sonnet-4.5\": {\n",
        "        \"input\": 3.00,\n",
        "        \"output\": 15.00,\n",
        "        \"context\": 200_000,\n",
        "        \"name\": \"Claude Sonnet 4.5\"\n",
        "    },\n",
        "    \"claude-opus-4.5\": {\n",
        "        \"input\": 5.00,\n",
        "        \"output\": 25.00,\n",
        "        \"context\": 200_000,\n",
        "        \"name\": \"Claude Opus 4.5\"\n",
        "    },\n",
        "    \"gpt-4o-mini\": {\n",
        "        \"input\": 0.15,\n",
        "        \"output\": 0.60,\n",
        "        \"context\": 128_000,\n",
        "        \"name\": \"GPT-4o-mini\"\n",
        "    },\n",
        "    \"gpt-4o\": {\n",
        "        \"input\": 2.50,\n",
        "        \"output\": 10.00,\n",
        "        \"context\": 128_000,\n",
        "        \"name\": \"GPT-4o\"\n",
        "    },\n",
        "    \"gemini-1.5-pro\": {\n",
        "        \"input\": 1.25,\n",
        "        \"output\": 5.00,\n",
        "        \"context\": 2_000_000,\n",
        "        \"name\": \"Gemini 1.5 Pro\"\n",
        "    }\n",
        "}\n",
        "\n",
        "# Display pricing table\n",
        "print(\"=\" * 80)\n",
        "print(\"CURRENT MODEL PRICING (January 2026)\")\n",
        "print(\"=\" * 80)\n",
        "print(f\"{'Model':<20} {'Input ($/1M)':<15} {'Output ($/1M)':<15} {'Context'}\")\n",
        "print(\"-\" * 80)\n",
        "for model_id, info in PRICING.items():\n",
        "    print(f\"{info['name']:<20} ${info['input']:<14.2f} ${info['output']:<14.2f} {info['context']:,}\")\n",
        "print(\"=\" * 80)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "## ðŸ”¢ Demo 1: Basic Token Counting\n",
        "\n",
        "Let's start simple - count tokens in different types of text."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import tiktoken\n",
        "\n",
        "def count_tokens(text: str) -> int:\n",
        "    \"\"\"Count tokens using GPT-4's tokenizer (good approximation for all models).\"\"\"\n",
        "    encoding = tiktoken.get_encoding(\"cl100k_base\")\n",
        "    return len(encoding.encode(text))\n",
        "\n",
        "def show_tokens(text: str, description: str = \"\"):\n",
        "    \"\"\"Display text with token count and breakdown.\"\"\"\n",
        "    encoding = tiktoken.get_encoding(\"cl100k_base\")\n",
        "    tokens = encoding.encode(text)\n",
        "    token_strings = [encoding.decode([token]) for token in tokens]\n",
        "    \n",
        "    print(f\"\\n{'='*60}\")\n",
        "    if description:\n",
        "        print(f\"Description: {description}\")\n",
        "    print(f\"Text: {text}\")\n",
        "    print(f\"Tokens: {token_strings}\")\n",
        "    print(f\"Token count: {len(tokens)}\")\n",
        "    print(f\"Characters: {len(text)}\")\n",
        "    print(f\"Ratio: {len(text)/len(tokens):.2f} chars/token\")\n",
        "    print(f\"{'='*60}\")\n",
        "\n",
        "# Examples from Chapter 2\n",
        "examples = [\n",
        "    (\"Hello world\", \"Simple English\"),\n",
        "    (\"interface GigabitEthernet0/0\", \"Cisco interface command\"),\n",
        "    (\"int Gi0/0\", \"Abbreviated version\"),\n",
        "    (\"192.168.1.1\", \"IP address\"),\n",
        "    (\"255.255.255.0\", \"Subnet mask\"),\n",
        "    (\"router bgp 65001\", \"BGP command\"),\n",
        "]\n",
        "\n",
        "for text, desc in examples:\n",
        "    show_tokens(text, desc)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### ðŸ’¡ Key Observations\n",
        "\n",
        "Notice:\n",
        "- Simple English: ~2-3 chars/token\n",
        "- Network configs: ~2-4 chars/token\n",
        "- IP addresses: Each dot (.) is a separate token\n",
        "- Abbreviated commands use fewer tokens (\"int Gi0/0\" vs \"interface GigabitEthernet0/0\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "## ðŸ’° Demo 2: Cost Calculator\n",
        "\n",
        "Now let's calculate costs across all models."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def calculate_cost(input_tokens: int, output_tokens: int, model: str) -> dict:\n",
        "    \"\"\"\n",
        "    Calculate cost for a given model.\n",
        "    \n",
        "    Returns dict with:\n",
        "    - input_cost: Cost of input tokens\n",
        "    - output_cost: Cost of output tokens\n",
        "    - total_cost: Total cost\n",
        "    - fits: Whether it fits in context window\n",
        "    \"\"\"\n",
        "    if model not in PRICING:\n",
        "        raise ValueError(f\"Unknown model: {model}\")\n",
        "    \n",
        "    pricing = PRICING[model]\n",
        "    \n",
        "    input_cost = (input_tokens / 1_000_000) * pricing[\"input\"]\n",
        "    output_cost = (output_tokens / 1_000_000) * pricing[\"output\"]\n",
        "    total_cost = input_cost + output_cost\n",
        "    \n",
        "    total_tokens = input_tokens + output_tokens\n",
        "    fits = total_tokens < pricing[\"context\"]\n",
        "    \n",
        "    return {\n",
        "        \"input_cost\": input_cost,\n",
        "        \"output_cost\": output_cost,\n",
        "        \"total_cost\": total_cost,\n",
        "        \"fits\": fits,\n",
        "        \"model_name\": pricing[\"name\"],\n",
        "        \"context_window\": pricing[\"context\"]\n",
        "    }\n",
        "\n",
        "# Example: 10,000-line router config\n",
        "input_tokens = 13_000  # ~10K line config + prompt\n",
        "output_tokens = 2_000  # Detailed analysis\n",
        "\n",
        "print(\"\\n\" + \"=\"*80)\n",
        "print(f\"COST ANALYSIS: {input_tokens:,} input tokens + {output_tokens:,} output tokens\")\n",
        "print(\"=\"*80)\n",
        "print(f\"{'Model':<20} {'Input':<10} {'Output':<10} {'Total':<10} {'Fits?'}\")\n",
        "print(\"-\"*80)\n",
        "\n",
        "for model_id in PRICING.keys():\n",
        "    result = calculate_cost(input_tokens, output_tokens, model_id)\n",
        "    fits_icon = \"âœ…\" if result[\"fits\"] else \"âŒ\"\n",
        "    print(f\"{result['model_name']:<20} ${result['input_cost']:.4f}   ${result['output_cost']:.4f}   ${result['total_cost']:.4f}   {fits_icon}\")\n",
        "\n",
        "print(\"=\"*80)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### ðŸ’¡ Key Insight\n",
        "\n",
        "Notice:\n",
        "- **Output tokens cost 3-5x more** than input tokens\n",
        "- GPT-4o-mini is **20x cheaper** than Claude Sonnet\n",
        "- All models fit this config in their context window"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "## ðŸ“ Demo 3: Analyze Network Configs\n",
        "\n",
        "Let's create sample network configs and analyze their token counts."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Sample configs of different sizes\n",
        "SMALL_CONFIG = \"\"\"!\n",
        "hostname Branch-Router-01\n",
        "!\n",
        "interface GigabitEthernet0/0\n",
        " ip address 192.168.1.1 255.255.255.0\n",
        " no shutdown\n",
        "!\n",
        "router ospf 1\n",
        " network 192.168.1.0 0.0.0.255 area 0\n",
        "!\n",
        "end\n",
        "\"\"\"\n",
        "\n",
        "MEDIUM_CONFIG = SMALL_CONFIG * 50  # Simulate 50 interfaces\n",
        "LARGE_CONFIG = SMALL_CONFIG * 500   # Simulate 500 interfaces\n",
        "\n",
        "def analyze_config(config: str, config_name: str, expected_output: int = 2000):\n",
        "    \"\"\"\n",
        "    Analyze a config and show token counts and costs across all models.\n",
        "    \"\"\"\n",
        "    tokens = count_tokens(config)\n",
        "    lines = len(config.split('\\n'))\n",
        "    \n",
        "    print(f\"\\n{'='*80}\")\n",
        "    print(f\"CONFIG ANALYSIS: {config_name}\")\n",
        "    print(\"=\"*80)\n",
        "    print(f\"Lines: {lines:,}\")\n",
        "    print(f\"Characters: {len(config):,}\")\n",
        "    print(f\"Tokens: {tokens:,}\")\n",
        "    print(f\"Chars/token: {len(config)/tokens:.2f}\")\n",
        "    print()\n",
        "    print(f\"Cost estimates (assuming {expected_output:,} output tokens):\")\n",
        "    print(\"-\"*80)\n",
        "    print(f\"{'Model':<20} {'Cost':<12} {'Monthly (100x)':<15} {'Fits?'}\")\n",
        "    print(\"-\"*80)\n",
        "    \n",
        "    for model_id in PRICING.keys():\n",
        "        result = calculate_cost(tokens, expected_output, model_id)\n",
        "        monthly = result['total_cost'] * 100\n",
        "        fits_icon = \"âœ…\" if result[\"fits\"] else \"âŒ\"\n",
        "        print(f\"{result['model_name']:<20} ${result['total_cost']:.4f}    ${monthly:.2f}          {fits_icon}\")\n",
        "    \n",
        "    print(\"=\"*80)\n",
        "\n",
        "# Analyze all three configs\n",
        "analyze_config(SMALL_CONFIG, \"Small Config (10 lines)\")\n",
        "analyze_config(MEDIUM_CONFIG, \"Medium Config (500 lines)\")\n",
        "analyze_config(LARGE_CONFIG, \"Large Config (5,000 lines)\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "## ðŸŽ¯ Lab 1: Interactive Token Counter\n",
        "\n",
        "**Your turn!** Paste your own configs or commands and see how they tokenize."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Interactive token counter\n",
        "your_text = input(\"Paste your config/command (or press Enter for example): \")\n",
        "\n",
        "if not your_text.strip():\n",
        "    your_text = \"interface GigabitEthernet0/0\\n ip address 10.0.0.1 255.255.255.0\"\n",
        "    print(f\"Using example: {your_text[:50]}...\")\n",
        "\n",
        "show_tokens(your_text, \"Your Input\")\n",
        "\n",
        "# Calculate cost\n",
        "tokens = count_tokens(your_text)\n",
        "print(\"\\nCost to analyze (assuming 2,000 token response):\")\n",
        "print(\"-\"*60)\n",
        "\n",
        "for model_id in [\"gpt-4o-mini\", \"claude-haiku-4.5\", \"claude-sonnet-4.5\"]:\n",
        "    result = calculate_cost(tokens, 2000, model_id)\n",
        "    print(f\"{result['model_name']:<20} ${result['total_cost']:.4f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "## ðŸ“Š Demo 4: Context Window Testing\n",
        "\n",
        "Let's see which models can handle large configs."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Test different config sizes\n",
        "test_sizes = [\n",
        "    (1_000, \"Small (1K lines)\"),\n",
        "    (10_000, \"Medium (10K lines)\"),\n",
        "    (50_000, \"Large (50K lines)\"),\n",
        "    (100_000, \"Very Large (100K lines)\"),\n",
        "    (500_000, \"Massive (500K lines)\"),\n",
        "]\n",
        "\n",
        "# Estimate tokens (assuming ~4 chars per line, ~2.5 tokens per 4 chars)\n",
        "def estimate_tokens_from_lines(lines: int) -> int:\n",
        "    return int(lines * 50 / 4)  # ~50 chars per line, ~4 chars per token\n",
        "\n",
        "print(\"\\n\" + \"=\"*80)\n",
        "print(\"CONTEXT WINDOW FIT TEST\")\n",
        "print(\"=\"*80)\n",
        "print(f\"{'Config Size':<20} {'Tokens':<12} {'GPT-4o':<10} {'Claude':<10} {'Gemini'}\")\n",
        "print(\"-\"*80)\n",
        "\n",
        "for lines, desc in test_sizes:\n",
        "    tokens = estimate_tokens_from_lines(lines)\n",
        "    \n",
        "    gpt_fit = \"âœ…\" if tokens < 128_000 else \"âŒ\"\n",
        "    claude_fit = \"âœ…\" if tokens < 200_000 else \"âŒ\"\n",
        "    gemini_fit = \"âœ…\" if tokens < 2_000_000 else \"âŒ\"\n",
        "    \n",
        "    print(f\"{desc:<20} {tokens:>10,}  {gpt_fit:<10} {claude_fit:<10} {gemini_fit}\")\n",
        "\n",
        "print(\"=\"*80)\n",
        "print(\"\\nKey Insights:\")\n",
        "print(\"- GPT-4o/4o-mini: Max ~100K lines (128K tokens)\")\n",
        "print(\"- Claude (all): Max ~160K lines (200K tokens)\")\n",
        "print(\"- Gemini 1.5 Pro: Max ~1.6M lines (2M tokens)\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "## ðŸ’µ Demo 5: Batch Processing Costs\n",
        "\n",
        "Calculate monthly costs for analyzing your entire network."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def calculate_batch_costs(device_count: int, avg_tokens: int, analyses_per_month: int):\n",
        "    \"\"\"\n",
        "    Calculate monthly costs for batch processing.\n",
        "    \"\"\"\n",
        "    total_analyses = device_count * analyses_per_month\n",
        "    output_tokens = 2000  # Assume 2K token response per analysis\n",
        "    \n",
        "    print(f\"\\n{'='*80}\")\n",
        "    print(f\"BATCH COST PROJECTION\")\n",
        "    print(\"=\"*80)\n",
        "    print(f\"Devices: {device_count:,}\")\n",
        "    print(f\"Avg tokens per config: {avg_tokens:,}\")\n",
        "    print(f\"Analyses per device per month: {analyses_per_month}\")\n",
        "    print(f\"Total analyses per month: {total_analyses:,}\")\n",
        "    print()\n",
        "    print(f\"{'Model':<20} {'Per Analysis':<15} {'Monthly':<15} {'Annual'}\")\n",
        "    print(\"-\"*80)\n",
        "    \n",
        "    for model_id in PRICING.keys():\n",
        "        result = calculate_cost(avg_tokens, output_tokens, model_id)\n",
        "        monthly = result['total_cost'] * total_analyses\n",
        "        annual = monthly * 12\n",
        "        \n",
        "        print(f\"{result['model_name']:<20} ${result['total_cost']:.4f}        ${monthly:>8.2f}      ${annual:>10.2f}\")\n",
        "    \n",
        "    print(\"=\"*80)\n",
        "\n",
        "# Example: 1,000 devices, analyze weekly\n",
        "calculate_batch_costs(\n",
        "    device_count=1000,\n",
        "    avg_tokens=12_000,  # ~10K line config\n",
        "    analyses_per_month=4  # Weekly\n",
        ")\n",
        "\n",
        "# Your network - customize these values!\n",
        "print(\"\\n\" + \"=\"*80)\n",
        "print(\"CALCULATE FOR YOUR NETWORK:\")\n",
        "print(\"=\"*80)\n",
        "\n",
        "try:\n",
        "    your_devices = int(input(\"How many devices? (default 100): \") or \"100\")\n",
        "    your_tokens = int(input(\"Avg tokens per config? (default 10000): \") or \"10000\")\n",
        "    your_frequency = int(input(\"Analyses per device per month? (default 4): \") or \"4\")\n",
        "    \n",
        "    calculate_batch_costs(your_devices, your_tokens, your_frequency)\n",
        "except:\n",
        "    print(\"Using default values...\")\n",
        "    calculate_batch_costs(100, 10000, 4)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "## ðŸŽ¯ Lab 2: Model Comparison for Your Use Case\n",
        "\n",
        "Compare models based on YOUR specific requirements."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Model selection helper\n",
        "def recommend_model(tokens: int, task_type: str, budget: str):\n",
        "    \"\"\"\n",
        "    Recommend the best model based on requirements.\n",
        "    \n",
        "    task_type: 'simple', 'analysis', 'critical'\n",
        "    budget: 'low', 'medium', 'high'\n",
        "    \"\"\"\n",
        "    recommendations = {\n",
        "        'simple': {\n",
        "            'low': 'gpt-4o-mini',\n",
        "            'medium': 'claude-haiku-4.5',\n",
        "            'high': 'claude-sonnet-4.5'\n",
        "        },\n",
        "        'analysis': {\n",
        "            'low': 'claude-haiku-4.5',\n",
        "            'medium': 'claude-sonnet-4.5',\n",
        "            'high': 'claude-sonnet-4.5'\n",
        "        },\n",
        "        'critical': {\n",
        "            'low': 'claude-sonnet-4.5',\n",
        "            'medium': 'claude-sonnet-4.5',\n",
        "            'high': 'claude-opus-4.5'\n",
        "        }\n",
        "    }\n",
        "    \n",
        "    model_id = recommendations[task_type][budget]\n",
        "    \n",
        "    # Check if it fits\n",
        "    context_limit = PRICING[model_id]['context']\n",
        "    fits = tokens < (context_limit * 0.9)  # 90% safety margin\n",
        "    \n",
        "    print(f\"\\n{'='*80}\")\n",
        "    print(f\"MODEL RECOMMENDATION\")\n",
        "    print(\"=\"*80)\n",
        "    print(f\"Your requirements:\")\n",
        "    print(f\"  - Task type: {task_type}\")\n",
        "    print(f\"  - Budget: {budget}\")\n",
        "    print(f\"  - Input tokens: {tokens:,}\")\n",
        "    print()\n",
        "    print(f\"Recommended: {PRICING[model_id]['name']}\")\n",
        "    print(f\"  - Context window: {context_limit:,} tokens\")\n",
        "    print(f\"  - Will it fit? {'âœ… Yes' if fits else 'âŒ No - Consider chunking or Gemini'}\")\n",
        "    print()\n",
        "    \n",
        "    # Show cost\n",
        "    result = calculate_cost(tokens, 2000, model_id)\n",
        "    print(f\"Cost per analysis: ${result['total_cost']:.4f}\")\n",
        "    print(f\"Cost for 1,000 analyses: ${result['total_cost'] * 1000:.2f}\")\n",
        "    print(\"=\"*80)\n",
        "    \n",
        "    return model_id\n",
        "\n",
        "# Examples\n",
        "print(\"\\nExample 1: Simple syntax check\")\n",
        "recommend_model(tokens=5000, task_type='simple', budget='low')\n",
        "\n",
        "print(\"\\nExample 2: Security analysis\")\n",
        "recommend_model(tokens=15000, task_type='analysis', budget='medium')\n",
        "\n",
        "print(\"\\nExample 3: Critical audit\")\n",
        "recommend_model(tokens=20000, task_type='critical', budget='high')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "## ðŸ“ Demo 6: Complete Token Calculator\n",
        "\n",
        "The complete production-ready tool with all features."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "#!/usr/bin/env python3\n",
        "\"\"\"\n",
        "Complete Token Calculator for Network Engineers\n",
        "Production-ready implementation\n",
        "\"\"\"\n",
        "\n",
        "import tiktoken\n",
        "from typing import Dict, List\n",
        "\n",
        "class TokenCalculator:\n",
        "    def __init__(self):\n",
        "        self.encoding = tiktoken.get_encoding(\"cl100k_base\")\n",
        "        self.pricing = PRICING\n",
        "    \n",
        "    def count_tokens(self, text: str) -> int:\n",
        "        \"\"\"Count tokens in text.\"\"\"\n",
        "        return len(self.encoding.encode(text))\n",
        "    \n",
        "    def analyze(self, text: str, expected_output: int = 2000) -> Dict:\n",
        "        \"\"\"\n",
        "        Complete analysis of text with costs for all models.\n",
        "        \"\"\"\n",
        "        input_tokens = self.count_tokens(text)\n",
        "        \n",
        "        results = {\n",
        "            'input_tokens': input_tokens,\n",
        "            'output_tokens': expected_output,\n",
        "            'characters': len(text),\n",
        "            'lines': len(text.split('\\n')),\n",
        "            'models': {}\n",
        "        }\n",
        "        \n",
        "        for model_id, pricing in self.pricing.items():\n",
        "            input_cost = (input_tokens / 1_000_000) * pricing['input']\n",
        "            output_cost = (expected_output / 1_000_000) * pricing['output']\n",
        "            total_cost = input_cost + output_cost\n",
        "            \n",
        "            fits = (input_tokens + expected_output) < pricing['context']\n",
        "            \n",
        "            results['models'][model_id] = {\n",
        "                'name': pricing['name'],\n",
        "                'input_cost': input_cost,\n",
        "                'output_cost': output_cost,\n",
        "                'total_cost': total_cost,\n",
        "                'fits': fits,\n",
        "                'context': pricing['context']\n",
        "            }\n",
        "        \n",
        "        return results\n",
        "    \n",
        "    def format_report(self, results: Dict) -> str:\n",
        "        \"\"\"Format results as a readable report.\"\"\"\n",
        "        report = []\n",
        "        report.append(\"=\"*80)\n",
        "        report.append(\"TOKEN ANALYSIS REPORT\")\n",
        "        report.append(\"=\"*80)\n",
        "        report.append(f\"Input: {results['input_tokens']:,} tokens ({results['characters']:,} chars, {results['lines']:,} lines)\")\n",
        "        report.append(f\"Expected output: {results['output_tokens']:,} tokens\")\n",
        "        report.append(\"\")\n",
        "        report.append(f\"{'Model':<20} {'Cost':<12} {'100x':<12} {'1000x':<12} {'Fits?'}\")\n",
        "        report.append(\"-\"*80)\n",
        "        \n",
        "        # Sort by cost\n",
        "        sorted_models = sorted(\n",
        "            results['models'].items(),\n",
        "            key=lambda x: x[1]['total_cost']\n",
        "        )\n",
        "        \n",
        "        for model_id, data in sorted_models:\n",
        "            cost_100 = data['total_cost'] * 100\n",
        "            cost_1000 = data['total_cost'] * 1000\n",
        "            fits_icon = \"âœ…\" if data['fits'] else \"âŒ\"\n",
        "            \n",
        "            report.append(\n",
        "                f\"{data['name']:<20} ${data['total_cost']:.4f}    \"\n",
        "                f\"${cost_100:>8.2f}   ${cost_1000:>8.2f}    {fits_icon}\"\n",
        "            )\n",
        "        \n",
        "        report.append(\"=\"*80)\n",
        "        return \"\\n\".join(report)\n",
        "\n",
        "# Test the calculator\n",
        "calc = TokenCalculator()\n",
        "\n",
        "# Analyze a sample config\n",
        "test_config = \"\"\"hostname Core-Router-01\n",
        "interface GigabitEthernet0/0\n",
        " ip address 10.0.1.1 255.255.255.252\n",
        " ip ospf cost 10\n",
        "!\n",
        "router ospf 1\n",
        " network 10.0.0.0 0.0.255.255 area 0\n",
        "!\n",
        "router bgp 65001\n",
        " neighbor 10.0.1.2 remote-as 65002\n",
        "!\n",
        "\"\"\" * 100  # Simulate larger config\n",
        "\n",
        "results = calc.analyze(test_config)\n",
        "print(calc.format_report(results))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "## ðŸŽ“ Self-Assessment\n",
        "\n",
        "Can you answer these questions?\n",
        "\n",
        "1. **How many tokens is the IP address \"192.168.1.1\"?**\n",
        "   <details>\n",
        "   <summary>Answer</summary>\n",
        "   7 tokens: [\"192\", \".\", \"168\", \".\", \"1\", \".\", \"1\"]\n",
        "   </details>\n",
        "\n",
        "2. **Which costs more: input tokens or output tokens?**\n",
        "   <details>\n",
        "   <summary>Answer</summary>\n",
        "   Output tokens cost 3-5x more than input tokens across all models.\n",
        "   </details>\n",
        "\n",
        "3. **What's the cheapest model for simple tasks?**\n",
        "   <details>\n",
        "   <summary>Answer</summary>\n",
        "   GPT-4o-mini at $0.15/$0.60 per million tokens.\n",
        "   </details>\n",
        "\n",
        "4. **Which model has the largest context window?**\n",
        "   <details>\n",
        "   <summary>Answer</summary>\n",
        "   Gemini 1.5 Pro with 2M tokens (10x larger than GPT-4o/Claude).\n",
        "   </details>\n",
        "\n",
        "5. **If a 10K-line config costs $0.069 with Sonnet, what's the monthly cost for 1,000 devices analyzed weekly?**\n",
        "   <details>\n",
        "   <summary>Answer</summary>\n",
        "   1,000 devices Ã— 4 weeks Ã— $0.069 = $276/month\n",
        "   </details>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "## ðŸŽ‰ Congratulations!\n",
        "\n",
        "You now have:\n",
        "\n",
        "âœ… A working token calculator for any network config  \n",
        "âœ… Cost comparison across all major models  \n",
        "âœ… Understanding of how network data tokenizes  \n",
        "âœ… Batch processing cost projections  \n",
        "âœ… Model selection framework  \n",
        "\n",
        "## ðŸ’¾ Save Your Work\n",
        "\n",
        "Download this notebook (File â†’ Download â†’ Download .ipynb) and save it to your toolkit!\n",
        "\n",
        "## ðŸš€ Next Steps\n",
        "\n",
        "**Chapter 3: Choosing the Right Model**\n",
        "- Benchmark models on your specific workloads\n",
        "- Understand quality vs cost tradeoffs\n",
        "- Build a model selection decision tree\n",
        "\n",
        "---\n",
        "\n",
        "**Questions?** Open an issue on [GitHub](https://github.com/eduardd76/AI_for_networking_and_security_engineers/issues)\n",
        "\n",
        "**Want more?** Check out the full book at [vExpertAI.com](https://vexpertai.com)"
      ]
    }
  ]
}