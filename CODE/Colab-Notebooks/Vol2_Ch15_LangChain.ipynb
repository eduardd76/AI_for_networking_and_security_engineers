{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Volume 2, Chapter 15: LangChain Integration
",
    "
",
    "**Framework patterns for network tasks**
",
    "
",
    "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/eduardd76/AI_for_networking_and_security_engineers/blob/master/CODE/Colab-Notebooks/Vol2_Ch15_LangChain.ipynb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup
",
    "!pip install -q langchain langchain-anthropic langchain-openai chromadb
",
    "
",
    "import os
",
    "from getpass import getpass
",
    "if 'ANTHROPIC_API_KEY' not in os.environ:
",
    "    os.environ['ANTHROPIC_API_KEY'] = getpass('Enter Anthropic API key: ')
",
    "if 'OPENAI_API_KEY' not in os.environ:
    os.environ['OPENAI_API_KEY'] = getpass('Enter OpenAI API key: ')
",
    "print(\"âœ“ Ready!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ðŸ“– Examples
",
    "
",
    "This notebook contains working examples from the chapter.
",
    "
",
    "**What you'll learn:**
",
    "- Simple chains
- Structured output
- Config generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_anthropic import ChatAnthropic
",
    "
",
    "llm = ChatAnthropic(model=\"claude-sonnet-4-20250514\", temperature=0)
",
    "
",
    "# Try the examples from the chapter
",
    "question = \"What is OSPF?\"
",
    "response = llm.invoke(question)
",
    "
",
    "print(f\"Question: {question}\")
",
    "print(f\"Answer: {response.content}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ðŸ’¡ Your Turn
",
    "
",
    "Modify the examples above or add your own!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code here
",
    "your_question = input(\"Ask a question: \")
",
    "response = llm.invoke(your_question)
",
    "print(response.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ðŸ“š Next Steps
",
    "
",
    "- Try other notebooks
",
    "- Modify examples with your network data
",
    "- Check the [full Python code](https://github.com/eduardd76/AI_for_networking_and_security_engineers) for more details"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}