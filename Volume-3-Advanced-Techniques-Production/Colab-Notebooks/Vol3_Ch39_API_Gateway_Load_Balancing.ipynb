{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Chapter 39: API Gateway & Load Balancing\n",
    "\n",
    "Run this notebook directly in Google Colab - no local Python needed!\n",
    "\n",
    "**Full code**: [GitHub](https://github.com/eduardd76/AI_for_networking_and_security_engineers/tree/main/CODE/Volume-3-Production-Systems/Chapter-39-API-Gateway-Load-Balancing)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup\n",
    "\n",
    "Install dependencies and configure API keys."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install dependencies\n",
    "!pip install -q requests flask anthropic pybreaker\n",
    "\n",
    "# Import and configure API key\n",
    "import os\n",
    "from getpass import getpass\n",
    "\n",
    "# Check for Colab secrets first\n",
    "try:\n",
    "    from google.colab import userdata\n",
    "    os.environ['ANTHROPIC_API_KEY'] = userdata.get('ANTHROPIC_API_KEY')\n",
    "    try:\n",
    "        os.environ['OPENAI_API_KEY'] = userdata.get('OPENAI_API_KEY')\n",
    "    except:\n",
    "        pass\n",
    "    print('✓ Using API keys from Colab secrets')\n",
    "except:\n",
    "    # Fall back to manual entry\n",
    "    if 'ANTHROPIC_API_KEY' not in os.environ:\n",
    "        os.environ['ANTHROPIC_API_KEY'] = getpass('Enter ANTHROPIC_API_KEY: ')\n",
    "    print('✓ API keys configured')\n",
    "\n",
    "print('\\n✅ Setup complete! Ready to run examples.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example 1: Simple Load Balancer\n",
    "\n",
    "Implement round-robin load balancing for API requests."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from typing import List, Dict, Any\n",
    "import time\n",
    "\n",
    "class SimpleLoadBalancer:\n",
    "    \"\"\"\n",
    "    Round-robin load balancer for API requests.\n",
    "    Distributes requests evenly across multiple backends.\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, backends: List[str]):\n",
    "        self.backends = backends\n",
    "        self.current_index = 0\n",
    "        self.request_count = {backend: 0 for backend in backends}\n",
    "    \n",
    "    def get_next_backend(self) -> str:\n",
    "        \"\"\"Get next backend using round-robin\"\"\"\n",
    "        backend = self.backends[self.current_index]\n",
    "        self.current_index = (self.current_index + 1) % len(self.backends)\n",
    "        self.request_count[backend] += 1\n",
    "        return backend\n",
    "    \n",
    "    def send_request(self, endpoint: str, data: Dict[str, Any]) -> Dict[str, Any]:\n",
    "        \"\"\"Send request to next backend\"\"\"\n",
    "        backend = self.get_next_backend()\n",
    "        url = f\"{backend}{endpoint}\"\n",
    "        \n",
    "        start_time = time.time()\n",
    "        \n",
    "        try:\n",
    "            # Simulate backend call\n",
    "            time.sleep(0.1)  # Simulate network latency\n",
    "            \n",
    "            return {\n",
    "                \"backend\": backend,\n",
    "                \"status\": \"success\",\n",
    "                \"data\": data,\n",
    "                \"latency_ms\": (time.time() - start_time) * 1000\n",
    "            }\n",
    "        except Exception as e:\n",
    "            return {\n",
    "                \"backend\": backend,\n",
    "                \"status\": \"error\",\n",
    "                \"error\": str(e),\n",
    "                \"latency_ms\": (time.time() - start_time) * 1000\n",
    "            }\n",
    "    \n",
    "    def get_stats(self) -> Dict[str, Any]:\n",
    "        \"\"\"Get load balancer statistics\"\"\"\n",
    "        total_requests = sum(self.request_count.values())\n",
    "        return {\n",
    "            \"total_requests\": total_requests,\n",
    "            \"backends\": len(self.backends),\n",
    "            \"distribution\": {\n",
    "                backend: {\n",
    "                    \"requests\": count,\n",
    "                    \"percentage\": (count / total_requests * 100) if total_requests > 0 else 0\n",
    "                }\n",
    "                for backend, count in self.request_count.items()\n",
    "            }\n",
    "        }\n",
    "\n",
    "# Test load balancer\n",
    "backends = [\n",
    "    \"http://backend-1:8000\",\n",
    "    \"http://backend-2:8000\",\n",
    "    \"http://backend-3:8000\"\n",
    "]\n",
    "\n",
    "lb = SimpleLoadBalancer(backends)\n",
    "\n",
    "print(\"Testing round-robin load balancing...\\n\")\n",
    "\n",
    "# Send 9 requests\n",
    "for i in range(9):\n",
    "    result = lb.send_request(\"/v1/chat/completions\", {\"query\": f\"request_{i}\"})\n",
    "    print(f\"Request {i+1}: routed to {result['backend']} ({result['latency_ms']:.1f}ms)\")\n",
    "\n",
    "# Show statistics\n",
    "print(\"\\nLoad Balancer Statistics:\")\n",
    "stats = lb.get_stats()\n",
    "print(f\"Total requests: {stats['total_requests']}\")\n",
    "print(f\"Backends: {stats['backends']}\")\n",
    "print(\"\\nDistribution:\")\n",
    "for backend, info in stats['distribution'].items():\n",
    "    print(f\"  {backend}: {info['requests']} requests ({info['percentage']:.1f}%)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example 2: Circuit Breaker Pattern\n",
    "\n",
    "Implement circuit breaker to prevent cascading failures."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pybreaker import CircuitBreaker\n",
    "import time\n",
    "import random\n",
    "\n",
    "# Configure circuit breaker\n",
    "breaker = CircuitBreaker(\n",
    "    fail_max=5,           # Open after 5 failures\n",
    "    timeout_duration=30,  # Stay open for 30 seconds\n",
    "    name='api_breaker'\n",
    ")\n",
    "\n",
    "@breaker\n",
    "def call_api_with_breaker(backend_id: int, request_id: int) -> Dict[str, Any]:\n",
    "    \"\"\"\n",
    "    Call API with circuit breaker protection.\n",
    "    Simulates failures to demonstrate circuit breaker behavior.\n",
    "    \"\"\"\n",
    "    # Simulate failures for first 5 requests\n",
    "    if request_id < 5:\n",
    "        raise Exception(f\"Backend {backend_id} error: Service unavailable\")\n",
    "    \n",
    "    # Simulate success after that\n",
    "    return {\n",
    "        \"backend_id\": backend_id,\n",
    "        \"status\": \"success\",\n",
    "        \"response\": f\"Request {request_id} processed successfully\"\n",
    "    }\n",
    "\n",
    "print(\"Testing circuit breaker pattern...\\n\")\n",
    "\n",
    "# Test circuit breaker\n",
    "for i in range(10):\n",
    "    try:\n",
    "        result = call_api_with_breaker(1, i)\n",
    "        print(f\"Request {i}: SUCCESS - {result['response']}\")\n",
    "    except Exception as e:\n",
    "        error_type = type(e).__name__\n",
    "        if error_type == \"CircuitBreakerError\":\n",
    "            print(f\"Request {i}: CIRCUIT BREAKER OPEN (fast fail)\")\n",
    "        else:\n",
    "            print(f\"Request {i}: FAILED - {str(e)}\")\n",
    "    \n",
    "    time.sleep(0.2)\n",
    "\n",
    "print(\"\\nCircuit Breaker State:\")\n",
    "print(f\"  State: {breaker.current_state}\")\n",
    "print(f\"  Failure count: {breaker.fail_counter}\")\n",
    "print(f\"  Expected close time: {breaker.opened_at + breaker.timeout_duration if breaker.opened_at else 'N/A'}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example 3: Retry Logic with Exponential Backoff\n",
    "\n",
    "Implement intelligent retry strategy for transient failures."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import random\n",
    "from typing import Dict, Any, Optional\n",
    "\n",
    "def call_api_with_retry(\n",
    "    url: str,\n",
    "    data: Dict[str, Any],\n",
    "    max_retries: int = 5,\n",
    "    base_delay: float = 1.0\n",
    ") -> Dict[str, Any]:\n",
    "    \"\"\"\n",
    "    Call API with exponential backoff retry logic.\n",
    "    \n",
    "    Args:\n",
    "        url: API endpoint\n",
    "        data: Request data\n",
    "        max_retries: Maximum retry attempts\n",
    "        base_delay: Initial delay in seconds\n",
    "    \"\"\"\n",
    "    for attempt in range(max_retries):\n",
    "        try:\n",
    "            # Simulate API call\n",
    "            # Fail first 3 attempts, succeed on 4th\n",
    "            if attempt < 3:\n",
    "                # Simulate different error types\n",
    "                error_type = random.choice([503, 429, \"timeout\"])\n",
    "                \n",
    "                if error_type == 429:\n",
    "                    # Rate limited - use Retry-After header\n",
    "                    retry_after = 2.0\n",
    "                    wait_time = retry_after\n",
    "                    print(f\"Attempt {attempt + 1}: Rate limited (429)\")\n",
    "                    print(f\"  Waiting {wait_time:.2f}s before retry\")\n",
    "                elif error_type == 503:\n",
    "                    # Server error - exponential backoff\n",
    "                    wait_time = base_delay * (2 ** attempt)\n",
    "                    jitter = random.uniform(0, wait_time * 0.1)\n",
    "                    total_wait = wait_time + jitter\n",
    "                    print(f\"Attempt {attempt + 1}: Server error (503)\")\n",
    "                    print(f\"  Waiting {total_wait:.2f}s before retry\")\n",
    "                    wait_time = total_wait\n",
    "                else:\n",
    "                    # Timeout - exponential backoff\n",
    "                    wait_time = base_delay * (2 ** attempt)\n",
    "                    jitter = random.uniform(0, wait_time * 0.1)\n",
    "                    total_wait = wait_time + jitter\n",
    "                    print(f\"Attempt {attempt + 1}: Timeout\")\n",
    "                    print(f\"  Waiting {total_wait:.2f}s before retry\")\n",
    "                    wait_time = total_wait\n",
    "                \n",
    "                time.sleep(wait_time)\n",
    "                continue\n",
    "            \n",
    "            # Success on 4th attempt\n",
    "            print(f\"Attempt {attempt + 1}: Success\")\n",
    "            return {\n",
    "                \"status\": \"success\",\n",
    "                \"data\": data,\n",
    "                \"attempts\": attempt + 1\n",
    "            }\n",
    "        \n",
    "        except Exception as e:\n",
    "            print(f\"Attempt {attempt + 1}: Exception - {str(e)}\")\n",
    "            if attempt < max_retries - 1:\n",
    "                wait_time = base_delay * (2 ** attempt)\n",
    "                print(f\"  Waiting {wait_time:.2f}s before retry\")\n",
    "                time.sleep(wait_time)\n",
    "                continue\n",
    "    \n",
    "    # All retries exhausted\n",
    "    return {\n",
    "        \"status\": \"failed\",\n",
    "        \"error\": f\"Failed after {max_retries} attempts\",\n",
    "        \"attempts\": max_retries\n",
    "    }\n",
    "\n",
    "print(\"Testing exponential backoff retry logic...\\n\")\n",
    "\n",
    "start_time = time.time()\n",
    "result = call_api_with_retry(\n",
    "    url=\"https://api.example.com/v1/chat\",\n",
    "    data={\"query\": \"test\"},\n",
    "    max_retries=5,\n",
    "    base_delay=1.0\n",
    ")\n",
    "total_time = time.time() - start_time\n",
    "\n",
    "print(f\"\\nFinal Result:\")\n",
    "print(f\"  Status: {result['status']}\")\n",
    "print(f\"  Attempts: {result['attempts']}\")\n",
    "print(f\"  Total time: {total_time:.2f}s\")\n",
    "\n",
    "if result['status'] == 'success':\n",
    "    print(f\"  Data: {result['data']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example 4: Request Routing and Health Checks\n",
    "\n",
    "Implement backend health monitoring with automatic failover."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List, Dict, Any, Optional\n",
    "from dataclasses import dataclass\n",
    "from datetime import datetime, timedelta\n",
    "import time\n",
    "import random\n",
    "\n",
    "@dataclass\n",
    "class Backend:\n",
    "    \"\"\"Backend server configuration\"\"\"\n",
    "    url: str\n",
    "    weight: int = 1\n",
    "    healthy: bool = True\n",
    "    fail_count: int = 0\n",
    "    max_fails: int = 3\n",
    "    last_check: Optional[datetime] = None\n",
    "    response_time_ms: float = 0.0\n",
    "\n",
    "class HealthAwareLoadBalancer:\n",
    "    \"\"\"\n",
    "    Load balancer with health checks and automatic failover.\n",
    "    Marks backends as unhealthy after consecutive failures.\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, backends: List[Backend], health_check_interval: int = 10):\n",
    "        self.backends = backends\n",
    "        self.health_check_interval = health_check_interval\n",
    "        self.current_index = 0\n",
    "        self.request_count = {backend.url: 0 for backend in backends}\n",
    "    \n",
    "    def check_backend_health(self, backend: Backend) -> bool:\n",
    "        \"\"\"Check if backend is healthy\"\"\"\n",
    "        try:\n",
    "            # Simulate health check\n",
    "            # Randomly mark some backends as unhealthy for demo\n",
    "            if random.random() < 0.2:  # 20% chance of failure\n",
    "                backend.fail_count += 1\n",
    "                if backend.fail_count >= backend.max_fails:\n",
    "                    backend.healthy = False\n",
    "                return False\n",
    "            else:\n",
    "                backend.fail_count = 0\n",
    "                backend.healthy = True\n",
    "                backend.last_check = datetime.now()\n",
    "                return True\n",
    "        except Exception as e:\n",
    "            backend.fail_count += 1\n",
    "            if backend.fail_count >= backend.max_fails:\n",
    "                backend.healthy = False\n",
    "            return False\n",
    "    \n",
    "    def get_healthy_backends(self) -> List[Backend]:\n",
    "        \"\"\"Get list of healthy backends\"\"\"\n",
    "        return [b for b in self.backends if b.healthy]\n",
    "    \n",
    "    def get_next_backend(self) -> Optional[Backend]:\n",
    "        \"\"\"Get next healthy backend using weighted round-robin\"\"\"\n",
    "        healthy_backends = self.get_healthy_backends()\n",
    "        \n",
    "        if not healthy_backends:\n",
    "            return None\n",
    "        \n",
    "        # Simple round-robin (can be extended to weighted)\n",
    "        backend = healthy_backends[self.current_index % len(healthy_backends)]\n",
    "        self.current_index += 1\n",
    "        self.request_count[backend.url] += 1\n",
    "        \n",
    "        return backend\n",
    "    \n",
    "    def send_request(self, endpoint: str, data: Dict[str, Any]) -> Dict[str, Any]:\n",
    "        \"\"\"Send request to healthy backend with automatic failover\"\"\"\n",
    "        max_attempts = len(self.backends)\n",
    "        \n",
    "        for attempt in range(max_attempts):\n",
    "            backend = self.get_next_backend()\n",
    "            \n",
    "            if not backend:\n",
    "                return {\n",
    "                    \"status\": \"error\",\n",
    "                    \"error\": \"No healthy backends available\"\n",
    "                }\n",
    "            \n",
    "            start_time = time.time()\n",
    "            \n",
    "            try:\n",
    "                # Simulate backend call\n",
    "                time.sleep(0.05)  # Simulate network latency\n",
    "                \n",
    "                # Simulate occasional failures\n",
    "                if random.random() < 0.1:  # 10% failure rate\n",
    "                    raise Exception(\"Backend error\")\n",
    "                \n",
    "                response_time = (time.time() - start_time) * 1000\n",
    "                backend.response_time_ms = response_time\n",
    "                \n",
    "                return {\n",
    "                    \"status\": \"success\",\n",
    "                    \"backend\": backend.url,\n",
    "                    \"data\": data,\n",
    "                    \"response_time_ms\": response_time,\n",
    "                    \"attempt\": attempt + 1\n",
    "                }\n",
    "            \n",
    "            except Exception as e:\n",
    "                backend.fail_count += 1\n",
    "                if backend.fail_count >= backend.max_fails:\n",
    "                    backend.healthy = False\n",
    "                    print(f\"  Backend {backend.url} marked unhealthy\")\n",
    "                \n",
    "                if attempt < max_attempts - 1:\n",
    "                    print(f\"  Attempt {attempt + 1} failed, trying next backend...\")\n",
    "                    continue\n",
    "        \n",
    "        return {\n",
    "            \"status\": \"error\",\n",
    "            \"error\": \"All backends failed\"\n",
    "        }\n",
    "    \n",
    "    def get_stats(self) -> Dict[str, Any]:\n",
    "        \"\"\"Get load balancer statistics\"\"\"\n",
    "        healthy = self.get_healthy_backends()\n",
    "        \n",
    "        return {\n",
    "            \"total_backends\": len(self.backends),\n",
    "            \"healthy_backends\": len(healthy),\n",
    "            \"unhealthy_backends\": len(self.backends) - len(healthy),\n",
    "            \"backends\": [\n",
    "                {\n",
    "                    \"url\": b.url,\n",
    "                    \"healthy\": b.healthy,\n",
    "                    \"fail_count\": b.fail_count,\n",
    "                    \"requests\": self.request_count[b.url],\n",
    "                    \"avg_response_ms\": b.response_time_ms\n",
    "                }\n",
    "                for b in self.backends\n",
    "            ]\n",
    "        }\n",
    "\n",
    "# Test health-aware load balancer\n",
    "backends = [\n",
    "    Backend(url=\"http://backend-1:8000\", weight=3),\n",
    "    Backend(url=\"http://backend-2:8000\", weight=2),\n",
    "    Backend(url=\"http://backend-3:8000\", weight=1)\n",
    "]\n",
    "\n",
    "lb = HealthAwareLoadBalancer(backends)\n",
    "\n",
    "print(\"Testing health-aware load balancing...\\n\")\n",
    "\n",
    "# Send 15 requests\n",
    "success_count = 0\n",
    "for i in range(15):\n",
    "    result = lb.send_request(\"/v1/chat\", {\"query\": f\"request_{i}\"})\n",
    "    \n",
    "    if result['status'] == 'success':\n",
    "        print(f\"Request {i+1}: SUCCESS via {result['backend']} ({result['response_time_ms']:.1f}ms)\")\n",
    "        success_count += 1\n",
    "    else:\n",
    "        print(f\"Request {i+1}: FAILED - {result['error']}\")\n",
    "\n",
    "# Show statistics\n",
    "print(\"\\nLoad Balancer Statistics:\")\n",
    "stats = lb.get_stats()\n",
    "print(f\"Total backends: {stats['total_backends']}\")\n",
    "print(f\"Healthy backends: {stats['healthy_backends']}\")\n",
    "print(f\"Unhealthy backends: {stats['unhealthy_backends']}\")\n",
    "print(f\"Success rate: {success_count}/15 ({success_count/15*100:.1f}%)\")\n",
    "print(\"\\nBackend Details:\")\n",
    "for backend in stats['backends']:\n",
    "    status = \"✓ HEALTHY\" if backend['healthy'] else \"✗ UNHEALTHY\"\n",
    "    print(f\"  {backend['url']}: {status}\")\n",
    "    print(f\"    Requests: {backend['requests']}\")\n",
    "    print(f\"    Fail count: {backend['fail_count']}\")\n",
    "    print(f\"    Avg response: {backend['avg_response_ms']:.1f}ms\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Next Steps\n",
    "\n",
    "- Full code: [Chapter 39 on GitHub](https://github.com/eduardd76/AI_for_networking_and_security_engineers/tree/main/CODE/Volume-3-Production-Systems/Chapter-39-API-Gateway-Load-Balancing)\n",
    "- Learn more: [vExpertAI.com](https://vexpertai.com)\n",
    "- Author: Eduard Dulharu ([@eduardd76](https://github.com/eduardd76))\n",
    "\n",
    "**Production Deployment:**\n",
    "- Use Nginx for production load balancing\n",
    "- Implement SSL/TLS termination\n",
    "- Configure health check probes\n",
    "- Set up monitoring with Prometheus\n",
    "- Deploy with Docker Swarm or Kubernetes"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
