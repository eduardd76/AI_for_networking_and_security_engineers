{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Chapter 41: Database Design for AI Systems\n",
    "\n",
    "Run this notebook directly in Google Colab - no local Python needed!\n",
    "\n",
    "**Full code**: [GitHub](https://github.com/eduardd76/AI_for_networking_and_security_engineers/tree/main/CODE/Volume-3-Production-Systems/Chapter-41-Database-Design)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup\n",
    "\n",
    "Install dependencies and configure database connection."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install dependencies\n",
    "!pip install -q psycopg2-binary sqlalchemy alembic\n",
    "\n",
    "import os\n",
    "from getpass import getpass\n",
    "\n",
    "print('✓ Dependencies installed')\n",
    "print('\\n✅ Setup complete! Ready to run examples.')\n",
    "print('\\n⚠️  Note: PostgreSQL examples require a running database.')\n",
    "print('   For testing without PostgreSQL, examples use SQLite.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example 1: SQLAlchemy Models for AI Conversations\n",
    "\n",
    "Define database models for storing AI conversations and messages."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sqlalchemy import create_engine, Column, String, Integer, Float, Text, DateTime, Boolean, ForeignKey, JSON\n",
    "from sqlalchemy.ext.declarative import declarative_base\n",
    "from sqlalchemy.orm import relationship, sessionmaker\n",
    "from datetime import datetime\n",
    "import uuid\n",
    "\n",
    "# Create base class for models\n",
    "Base = declarative_base()\n",
    "\n",
    "# Define models\n",
    "class User(Base):\n",
    "    \"\"\"User model\"\"\"\n",
    "    __tablename__ = 'users'\n",
    "    \n",
    "    id = Column(String(36), primary_key=True, default=lambda: str(uuid.uuid4()))\n",
    "    email = Column(String(255), unique=True, nullable=False)\n",
    "    name = Column(String(255), nullable=False)\n",
    "    role = Column(String(50), default='user')\n",
    "    is_active = Column(Boolean, default=True)\n",
    "    created_at = Column(DateTime, default=datetime.utcnow)\n",
    "    \n",
    "    # Relationships\n",
    "    conversations = relationship('Conversation', back_populates='user')\n",
    "\n",
    "class Conversation(Base):\n",
    "    \"\"\"Conversation model\"\"\"\n",
    "    __tablename__ = 'conversations'\n",
    "    \n",
    "    id = Column(String(36), primary_key=True, default=lambda: str(uuid.uuid4()))\n",
    "    user_id = Column(String(36), ForeignKey('users.id'), nullable=False)\n",
    "    title = Column(String(500))\n",
    "    model = Column(String(100), nullable=False)\n",
    "    created_at = Column(DateTime, default=datetime.utcnow)\n",
    "    updated_at = Column(DateTime, default=datetime.utcnow, onupdate=datetime.utcnow)\n",
    "    is_archived = Column(Boolean, default=False)\n",
    "    metadata = Column(JSON, default={})\n",
    "    \n",
    "    # Relationships\n",
    "    user = relationship('User', back_populates='conversations')\n",
    "    messages = relationship('Message', back_populates='conversation', cascade='all, delete-orphan')\n",
    "\n",
    "class Message(Base):\n",
    "    \"\"\"Message model\"\"\"\n",
    "    __tablename__ = 'messages'\n",
    "    \n",
    "    id = Column(String(36), primary_key=True, default=lambda: str(uuid.uuid4()))\n",
    "    conversation_id = Column(String(36), ForeignKey('conversations.id'), nullable=False)\n",
    "    role = Column(String(20), nullable=False)  # 'user', 'assistant', 'system'\n",
    "    content = Column(Text, nullable=False)\n",
    "    model = Column(String(100))\n",
    "    tokens_input = Column(Integer)\n",
    "    tokens_output = Column(Integer)\n",
    "    cost_usd = Column(Float)\n",
    "    created_at = Column(DateTime, default=datetime.utcnow)\n",
    "    metadata = Column(JSON, default={})\n",
    "    \n",
    "    # Relationships\n",
    "    conversation = relationship('Conversation', back_populates='messages')\n",
    "\n",
    "class APIUsage(Base):\n",
    "    \"\"\"API usage tracking\"\"\"\n",
    "    __tablename__ = 'api_usage'\n",
    "    \n",
    "    id = Column(Integer, primary_key=True, autoincrement=True)\n",
    "    user_id = Column(String(36), ForeignKey('users.id'))\n",
    "    model = Column(String(100), nullable=False)\n",
    "    endpoint = Column(String(200), nullable=False)\n",
    "    tokens_input = Column(Integer, nullable=False)\n",
    "    tokens_output = Column(Integer, nullable=False)\n",
    "    cost_usd = Column(Float, nullable=False)\n",
    "    latency_ms = Column(Integer)\n",
    "    status = Column(String(20), nullable=False)\n",
    "    recorded_at = Column(DateTime, default=datetime.utcnow)\n",
    "\n",
    "# Create SQLite database (for testing)\n",
    "engine = create_engine('sqlite:///ai_system.db', echo=False)\n",
    "Base.metadata.create_all(engine)\n",
    "\n",
    "# Create session\n",
    "Session = sessionmaker(bind=engine)\n",
    "session = Session()\n",
    "\n",
    "print(\"Database Models Created:\")\n",
    "print(f\"  Tables: {', '.join([table.name for table in Base.metadata.sorted_tables])}\")\n",
    "print(f\"  Database: sqlite:///ai_system.db\")\n",
    "\n",
    "# Create sample user\n",
    "user = User(\n",
    "    email=\"engineer@company.com\",\n",
    "    name=\"John Engineer\",\n",
    "    role=\"user\"\n",
    ")\n",
    "session.add(user)\n",
    "session.commit()\n",
    "\n",
    "print(f\"\\nCreated user: {user.email} (ID: {user.id})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example 2: Creating and Querying Conversations\n",
    "\n",
    "Store AI conversations with messages and track token usage."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sqlalchemy import func\n",
    "from datetime import datetime, timedelta\n",
    "\n",
    "# Create a conversation\n",
    "conversation = Conversation(\n",
    "    user_id=user.id,\n",
    "    title=\"BGP Configuration Analysis\",\n",
    "    model=\"claude-sonnet-4-5\",\n",
    "    metadata={\"source\": \"cli\", \"device\": \"router01\"}\n",
    ")\n",
    "session.add(conversation)\n",
    "session.commit()\n",
    "\n",
    "print(f\"Created conversation: {conversation.title}\")\n",
    "print(f\"  ID: {conversation.id}\")\n",
    "print(f\"  Model: {conversation.model}\")\n",
    "print(f\"  Created: {conversation.created_at}\")\n",
    "\n",
    "# Add messages to conversation\n",
    "user_message = Message(\n",
    "    conversation_id=conversation.id,\n",
    "    role='user',\n",
    "    content=\"Analyze this BGP config and identify potential issues\",\n",
    "    metadata={\"device\": \"router01\"}\n",
    ")\n",
    "session.add(user_message)\n",
    "\n",
    "assistant_message = Message(\n",
    "    conversation_id=conversation.id,\n",
    "    role='assistant',\n",
    "    content=\"I found 3 issues: 1) Missing route-map on neighbor...\",\n",
    "    model=\"claude-sonnet-4-5\",\n",
    "    tokens_input=1250,\n",
    "    tokens_output=890,\n",
    "    cost_usd=0.015,\n",
    "    metadata={\"confidence\": 0.95}\n",
    ")\n",
    "session.add(assistant_message)\n",
    "session.commit()\n",
    "\n",
    "print(f\"\\nAdded {len(conversation.messages)} messages to conversation\")\n",
    "\n",
    "# Record API usage\n",
    "api_usage = APIUsage(\n",
    "    user_id=user.id,\n",
    "    model=\"claude-sonnet-4-5\",\n",
    "    endpoint=\"/v1/messages\",\n",
    "    tokens_input=1250,\n",
    "    tokens_output=890,\n",
    "    cost_usd=0.015,\n",
    "    latency_ms=2345,\n",
    "    status=\"success\"\n",
    ")\n",
    "session.add(api_usage)\n",
    "session.commit()\n",
    "\n",
    "print(\"\\nRecorded API usage\")\n",
    "\n",
    "# Query recent conversations\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"Recent Conversations:\")\n",
    "recent = session.query(Conversation).filter_by(\n",
    "    user_id=user.id,\n",
    "    is_archived=False\n",
    ").order_by(Conversation.created_at.desc()).limit(5).all()\n",
    "\n",
    "for conv in recent:\n",
    "    print(f\"\\n  {conv.title}\")\n",
    "    print(f\"    ID: {conv.id}\")\n",
    "    print(f\"    Model: {conv.model}\")\n",
    "    print(f\"    Messages: {len(conv.messages)}\")\n",
    "    print(f\"    Created: {conv.created_at}\")\n",
    "\n",
    "# Calculate total costs\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"Cost Analysis:\")\n",
    "\n",
    "total_cost = session.query(func.sum(Message.cost_usd)).filter(\n",
    "    Message.conversation_id == Conversation.id,\n",
    "    Conversation.user_id == user.id\n",
    ").scalar() or 0\n",
    "\n",
    "total_tokens_in = session.query(func.sum(Message.tokens_input)).filter(\n",
    "    Message.conversation_id == Conversation.id,\n",
    "    Conversation.user_id == user.id\n",
    ").scalar() or 0\n",
    "\n",
    "total_tokens_out = session.query(func.sum(Message.tokens_output)).filter(\n",
    "    Message.conversation_id == Conversation.id,\n",
    "    Conversation.user_id == user.id\n",
    ").scalar() or 0\n",
    "\n",
    "print(f\"  Total cost: ${total_cost:.3f}\")\n",
    "print(f\"  Input tokens: {total_tokens_in:,}\")\n",
    "print(f\"  Output tokens: {total_tokens_out:,}\")\n",
    "print(f\"  Total tokens: {total_tokens_in + total_tokens_out:,}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example 3: Database Migrations with Alembic\n",
    "\n",
    "Manage schema changes with Alembic migrations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Note: This example demonstrates migration concepts\n",
    "# In production, run `alembic init migrations` and use CLI commands\n",
    "\n",
    "print(\"Alembic Migration Workflow:\\n\")\n",
    "print(\"1. Initialize Alembic:\")\n",
    "print(\"   $ alembic init migrations\")\n",
    "print(\"\")\n",
    "print(\"2. Configure alembic.ini:\")\n",
    "print(\"   sqlalchemy.url = postgresql://user:pass@localhost/ai_system\")\n",
    "print(\"\")\n",
    "print(\"3. Create migration:\")\n",
    "print(\"   $ alembic revision --autogenerate -m 'add_embedding_column'\")\n",
    "print(\"\")\n",
    "print(\"4. Apply migration:\")\n",
    "print(\"   $ alembic upgrade head\")\n",
    "print(\"\")\n",
    "print(\"5. Rollback migration:\")\n",
    "print(\"   $ alembic downgrade -1\")\n",
    "\n",
    "# Example migration file structure\n",
    "migration_example = '''\n",
    "\"\"\"add_embedding_column\n",
    "\n",
    "Revision ID: abc123def456\n",
    "\"\"\"\n",
    "from alembic import op\n",
    "import sqlalchemy as sa\n",
    "\n",
    "def upgrade():\n",
    "    # Add embedding column for vector search\n",
    "    op.add_column('messages',\n",
    "        sa.Column('embedding', sa.ARRAY(sa.Float), nullable=True)\n",
    "    )\n",
    "    \n",
    "    # Add model_version column\n",
    "    op.add_column('messages',\n",
    "        sa.Column('model_version', sa.String(50), nullable=True)\n",
    "    )\n",
    "\n",
    "def downgrade():\n",
    "    # Remove columns\n",
    "    op.drop_column('messages', 'embedding')\n",
    "    op.drop_column('messages', 'model_version')\n",
    "'''\n",
    "\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"Example Migration File:\\n\")\n",
    "print(migration_example)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example 4: Backup and Performance Optimization\n",
    "\n",
    "Demonstrate backup strategies and query optimization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sqlalchemy import text, inspect\n",
    "import time\n",
    "\n",
    "print(\"Database Performance and Backup\\n\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# Create additional test data for performance testing\n",
    "print(\"\\n1. Creating test data...\")\n",
    "for i in range(10):\n",
    "    conv = Conversation(\n",
    "        user_id=user.id,\n",
    "        title=f\"Test Conversation {i+1}\",\n",
    "        model=\"claude-sonnet-4-5\",\n",
    "        metadata={\"test\": True}\n",
    "    )\n",
    "    session.add(conv)\n",
    "    \n",
    "    # Add messages\n",
    "    for j in range(5):\n",
    "        msg = Message(\n",
    "            conversation_id=conv.id,\n",
    "            role='user' if j % 2 == 0 else 'assistant',\n",
    "            content=f\"Message {j+1}\",\n",
    "            tokens_input=100,\n",
    "            tokens_output=150,\n",
    "            cost_usd=0.002\n",
    "        )\n",
    "        session.add(msg)\n",
    "\n",
    "session.commit()\n",
    "print(\"   Created 10 conversations with 50 messages\")\n",
    "\n",
    "# Query with joins (unoptimized)\n",
    "print(\"\\n2. Query performance comparison:\")\n",
    "\n",
    "start = time.time()\n",
    "results = session.query(Message).join(Conversation).filter(\n",
    "    Conversation.user_id == user.id\n",
    ").all()\n",
    "duration1 = (time.time() - start) * 1000\n",
    "print(f\"   Query without eager loading: {duration1:.2f}ms ({len(results)} messages)\")\n",
    "\n",
    "# Query with eager loading (optimized)\n",
    "from sqlalchemy.orm import joinedload\n",
    "\n",
    "start = time.time()\n",
    "results = session.query(Message).options(\n",
    "    joinedload(Message.conversation)\n",
    ").join(Conversation).filter(\n",
    "    Conversation.user_id == user.id\n",
    ").all()\n",
    "duration2 = (time.time() - start) * 1000\n",
    "print(f\"   Query with eager loading: {duration2:.2f}ms ({len(results)} messages)\")\n",
    "print(f\"   Performance improvement: {((duration1 - duration2) / duration1 * 100):.1f}%\")\n",
    "\n",
    "# Database statistics\n",
    "print(\"\\n3. Database Statistics:\")\n",
    "inspector = inspect(engine)\n",
    "\n",
    "for table_name in inspector.get_table_names():\n",
    "    count = session.query(Base.metadata.tables[table_name]).count()\n",
    "    print(f\"   {table_name}: {count} rows\")\n",
    "\n",
    "# Backup strategy (conceptual)\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"Backup Strategy:\\n\")\n",
    "print(\"PostgreSQL backup commands:\")\n",
    "print(\"  Full backup:\")\n",
    "print(\"    $ pg_dump -h localhost -U postgres -F c -f backup.dump ai_system\")\n",
    "print(\"\")\n",
    "print(\"  Restore:\")\n",
    "print(\"    $ pg_restore -h localhost -U postgres -d ai_system -c backup.dump\")\n",
    "print(\"\")\n",
    "print(\"  Schema only:\")\n",
    "print(\"    $ pg_dump -h localhost -U postgres --schema-only -f schema.sql ai_system\")\n",
    "print(\"\")\n",
    "print(\"Recommended schedule:\")\n",
    "print(\"  - Daily full backups (retain 7 days)\")\n",
    "print(\"  - Hourly WAL archiving (point-in-time recovery)\")\n",
    "print(\"  - Weekly uploads to S3/Azure Blob\")\n",
    "\n",
    "# Indexing recommendations\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"Index Recommendations:\\n\")\n",
    "print(\"CREATE INDEX idx_messages_conversation_id ON messages(conversation_id);\")\n",
    "print(\"CREATE INDEX idx_messages_created_at ON messages(created_at DESC);\")\n",
    "print(\"CREATE INDEX idx_conversations_user_date ON conversations(user_id, created_at DESC);\")\n",
    "print(\"CREATE INDEX idx_api_usage_user_time ON api_usage(user_id, recorded_at DESC);\")\n",
    "print(\"CREATE INDEX idx_conversations_metadata ON conversations USING GIN (metadata);\")\n",
    "\n",
    "print(\"\\n✅ Examples complete!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example 5: Cost Tracking and Analytics\n",
    "\n",
    "Query cost data and generate analytics reports."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sqlalchemy import func, extract, case\n",
    "from datetime import datetime, timedelta\n",
    "\n",
    "print(\"Cost Analytics Report\\n\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# Total costs by model\n",
    "print(\"\\n1. Cost by Model:\")\n",
    "model_costs = session.query(\n",
    "    Message.model,\n",
    "    func.count(Message.id).label('message_count'),\n",
    "    func.sum(Message.tokens_input).label('total_input'),\n",
    "    func.sum(Message.tokens_output).label('total_output'),\n",
    "    func.sum(Message.cost_usd).label('total_cost')\n",
    ").filter(\n",
    "    Message.model.isnot(None)\n",
    ").group_by(Message.model).all()\n",
    "\n",
    "for row in model_costs:\n",
    "    print(f\"\\n   {row.model}:\")\n",
    "    print(f\"     Messages: {row.message_count}\")\n",
    "    print(f\"     Tokens: {row.total_input:,} in / {row.total_output:,} out\")\n",
    "    print(f\"     Cost: ${row.total_cost:.3f}\")\n",
    "\n",
    "# Daily cost trends (last 7 days)\n",
    "print(\"\\n2. Daily Cost Trends:\")\n",
    "week_ago = datetime.now() - timedelta(days=7)\n",
    "\n",
    "daily_costs = session.query(\n",
    "    func.date(APIUsage.recorded_at).label('date'),\n",
    "    func.count(APIUsage.id).label('requests'),\n",
    "    func.sum(APIUsage.cost_usd).label('cost'),\n",
    "    func.avg(APIUsage.latency_ms).label('avg_latency')\n",
    ").filter(\n",
    "    APIUsage.recorded_at >= week_ago\n",
    ").group_by(func.date(APIUsage.recorded_at)).all()\n",
    "\n",
    "if daily_costs:\n",
    "    for row in daily_costs:\n",
    "        print(f\"   {row.date}: {row.requests} requests, ${row.cost:.3f}, {row.avg_latency:.0f}ms avg\")\n",
    "else:\n",
    "    print(\"   No data for last 7 days (new database)\")\n",
    "\n",
    "# User statistics\n",
    "print(\"\\n3. User Activity:\")\n",
    "user_stats = session.query(\n",
    "    User.email,\n",
    "    func.count(Conversation.id).label('conversations'),\n",
    "    func.count(Message.id).label('messages'),\n",
    "    func.sum(Message.cost_usd).label('total_cost')\n",
    ").join(Conversation).join(Message).group_by(User.email).all()\n",
    "\n",
    "for row in user_stats:\n",
    "    print(f\"\\n   {row.email}:\")\n",
    "    print(f\"     Conversations: {row.conversations}\")\n",
    "    print(f\"     Messages: {row.messages}\")\n",
    "    print(f\"     Total cost: ${row.total_cost:.3f}\")\n",
    "\n",
    "# Cost projections\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"Monthly Projections:\\n\")\n",
    "\n",
    "# Calculate average daily cost\n",
    "total_days = 30  # Assume 30 days of data\n",
    "total_cost_all = session.query(func.sum(Message.cost_usd)).scalar() or 0\n",
    "daily_avg = total_cost_all / total_days if total_days > 0 else 0\n",
    "\n",
    "monthly_projection = daily_avg * 30\n",
    "annual_projection = monthly_projection * 12\n",
    "\n",
    "print(f\"   Daily average: ${daily_avg:.2f}\")\n",
    "print(f\"   Monthly projection: ${monthly_projection:.2f}\")\n",
    "print(f\"   Annual projection: ${annual_projection:.2f}\")\n",
    "\n",
    "# Cost breakdown by role\n",
    "print(\"\\n4. Cost by Message Role:\")\n",
    "role_costs = session.query(\n",
    "    Message.role,\n",
    "    func.count(Message.id).label('count'),\n",
    "    func.sum(Message.cost_usd).label('cost')\n",
    ").filter(\n",
    "    Message.cost_usd.isnot(None)\n",
    ").group_by(Message.role).all()\n",
    "\n",
    "for row in role_costs:\n",
    "    print(f\"   {row.role}: {row.count} messages, ${row.cost:.3f}\")\n",
    "\n",
    "print(\"\\n✅ Analytics complete!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Next Steps\n",
    "\n",
    "- Full code: [Chapter 41 on GitHub](https://github.com/eduardd76/AI_for_networking_and_security_engineers/tree/main/CODE/Volume-3-Production-Systems/Chapter-41-Database-Design)\n",
    "- Learn more: [vExpertAI.com](https://vexpertai.com)\n",
    "- Author: Eduard Dulharu ([@eduardd76](https://github.com/eduardd76))\n",
    "\n",
    "**Production Deployment:**\n",
    "- Use PostgreSQL for production\n",
    "- Implement connection pooling with PgBouncer\n",
    "- Set up automated backups with pg_dump\n",
    "- Configure WAL archiving for point-in-time recovery\n",
    "- Add indexes for common query patterns\n",
    "- Partition large tables by date\n",
    "- Monitor query performance with EXPLAIN ANALYZE"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
