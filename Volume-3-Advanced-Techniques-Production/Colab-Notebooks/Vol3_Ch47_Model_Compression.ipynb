{
 "nbformat": 4,
 "nbformat_minor": 0,
 "metadata": {
  "colab": {
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Chapter 47: Model Compression - Quantization and Pruning\n",
    "Reduce model size while preserving accuracy.\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "import numpy as np\n",
    "print(\"Model Compression ready\")\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "np.random.seed(42)\n",
    "W=np.random.randn(256,256).astype(\"float32\")\n",
    "mn,mx=W.min(),W.max(); scale=(mx-mn)/255; zp=-round(mn/scale)\n",
    "q=np.clip(np.round(W/scale+zp),0,255).astype(\"uint8\")\n",
    "dq=(q.astype(\"float32\")-zp)*scale; mse=float(np.mean((W-dq)**2))\n",
    "print(f\"FP32: {W.nbytes:,}B | INT8: {q.nbytes:,}B | ratio: {W.nbytes/q.nbytes:.1f}x | MSE: {mse:.6f}\")\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "for sp in [0.3,0.5,0.7,0.9]:\n",
    "    thr=np.percentile(np.abs(W),sp*100)\n",
    "    mask=np.abs(W)>thr; actual=1-mask.sum()/mask.size\n",
    "    print(f\"Target {sp:.0%}: actual={actual:.1%}, nonzero={mask.sum():,}/{W.size:,}\")\n",
    "print(\"Compression analysis for 7B params:\")\n",
    "orig=7_000_000_000\n",
    "for bits in [16,8,4,2]: print(f\"  {bits}-bit: {32/bits:.1f}x compression, ~{orig*bits/8/1e9:.1f}GB\")\n",
    "for sp in [0.5,0.7,0.9]: print(f\"  {sp:.0%} prune: ~{orig*4*(1-sp)/1e9:.1f}GB\")\n"
   ],
   "outputs": [],
   "execution_count": null
  }
 ]
}