{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Chapter 38: FastAPI Server & MCP Integration\n",
    "\n",
    "Run this notebook directly in Google Colab - no local Python needed!\n",
    "\n",
    "**Full code**: [GitHub](https://github.com/eduardd76/AI_for_networking_and_security_engineers/tree/main/CODE/Volume-3-Production-Systems/Chapter-38-FastAPI-Server-MCP)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup\n",
    "\n",
    "Install dependencies and configure API keys."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install dependencies\n",
    "!pip install -q fastapi uvicorn pydantic anthropic requests netmiko psutil\n",
    "\n",
    "# Import and configure API key\n",
    "import os\n",
    "from getpass import getpass\n",
    "\n",
    "# Check for Colab secrets first\n",
    "try:\n",
    "    from google.colab import userdata\n",
    "    os.environ['ANTHROPIC_API_KEY'] = userdata.get('ANTHROPIC_API_KEY')\n",
    "    print('✓ Using API keys from Colab secrets')\n",
    "except:\n",
    "    # Fall back to manual entry\n",
    "    if 'ANTHROPIC_API_KEY' not in os.environ:\n",
    "        os.environ['ANTHROPIC_API_KEY'] = getpass('Enter ANTHROPIC_API_KEY: ')\n",
    "    print('✓ API keys configured')\n",
    "\n",
    "print('\\n✅ Setup complete! Ready to run examples.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example 1: Basic FastAPI Server\n",
    "\n",
    "Create a production FastAPI server with health checks and request validation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from fastapi import FastAPI, HTTPException\n",
    "from pydantic import BaseModel, Field, validator\n",
    "from typing import List, Optional, Dict, Any\n",
    "from datetime import datetime\n",
    "import ipaddress\n",
    "\n",
    "# Initialize FastAPI app\n",
    "app = FastAPI(\n",
    "    title=\"Network AI Operations API\",\n",
    "    description=\"Production API for AI-powered network operations\",\n",
    "    version=\"1.0.0\"\n",
    ")\n",
    "\n",
    "# Request/Response models\n",
    "class DeviceQuery(BaseModel):\n",
    "    \"\"\"Request model for device queries\"\"\"\n",
    "    device_ip: str = Field(..., description=\"Device IP address\")\n",
    "    commands: List[str] = Field(..., description=\"Commands to execute\")\n",
    "    timeout: Optional[int] = Field(30, description=\"Timeout in seconds\")\n",
    "\n",
    "    @validator('device_ip')\n",
    "    def validate_ip(cls, v):\n",
    "        \"\"\"Validate IP address format\"\"\"\n",
    "        try:\n",
    "            ipaddress.ip_address(v)\n",
    "            return v\n",
    "        except ValueError:\n",
    "            raise ValueError(f\"Invalid IP address: {v}\")\n",
    "\n",
    "    @validator('commands')\n",
    "    def validate_commands(cls, v):\n",
    "        \"\"\"Ensure commands list is not empty\"\"\"\n",
    "        if not v:\n",
    "            raise ValueError(\"Commands list cannot be empty\")\n",
    "        return v\n",
    "\n",
    "class HealthResponse(BaseModel):\n",
    "    \"\"\"Health check response\"\"\"\n",
    "    status: str\n",
    "    timestamp: datetime\n",
    "    version: str\n",
    "    uptime_seconds: float\n",
    "\n",
    "# Global state\n",
    "START_TIME = datetime.now()\n",
    "\n",
    "@app.get(\"/\")\n",
    "async def root():\n",
    "    \"\"\"Root endpoint\"\"\"\n",
    "    return {\n",
    "        \"service\": \"Network AI Operations API\",\n",
    "        \"version\": \"1.0.0\",\n",
    "        \"docs\": \"/docs\"\n",
    "    }\n",
    "\n",
    "@app.get(\"/health\", response_model=HealthResponse)\n",
    "async def health_check():\n",
    "    \"\"\"Health check endpoint\"\"\"\n",
    "    uptime = (datetime.now() - START_TIME).total_seconds()\n",
    "    return HealthResponse(\n",
    "        status=\"healthy\",\n",
    "        timestamp=datetime.now(),\n",
    "        version=\"1.0.0\",\n",
    "        uptime_seconds=uptime\n",
    "    )\n",
    "\n",
    "@app.post(\"/query-device\")\n",
    "async def query_device(query: DeviceQuery):\n",
    "    \"\"\"Query network device (simulated)\"\"\"\n",
    "    return {\n",
    "        \"device_ip\": query.device_ip,\n",
    "        \"commands_executed\": len(query.commands),\n",
    "        \"status\": \"success\",\n",
    "        \"timestamp\": datetime.now()\n",
    "    }\n",
    "\n",
    "# Test the endpoints\n",
    "print(\"FastAPI server configuration:\")\n",
    "print(f\"  Title: {app.title}\")\n",
    "print(f\"  Version: {app.version}\")\n",
    "print(f\"  Endpoints: {len(app.routes)}\")\n",
    "print(\"\\nExample request:\")\n",
    "\n",
    "# Simulate a request\n",
    "test_query = DeviceQuery(\n",
    "    device_ip=\"192.168.1.1\",\n",
    "    commands=[\"show version\", \"show ip interface brief\"]\n",
    ")\n",
    "print(f\"  Device IP: {test_query.device_ip}\")\n",
    "print(f\"  Commands: {test_query.commands}\")\n",
    "print(f\"  Timeout: {test_query.timeout}s\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example 2: MCP Server Implementation\n",
    "\n",
    "Implement Model Context Protocol for standardized tool calling."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from fastapi import FastAPI\n",
    "from pydantic import BaseModel\n",
    "from typing import List, Dict, Any, Optional\n",
    "from datetime import datetime\n",
    "import time\n",
    "\n",
    "app = FastAPI(title=\"MCP Network Operations Server\")\n",
    "\n",
    "# MCP Protocol Models\n",
    "class MCPTool(BaseModel):\n",
    "    \"\"\"MCP tool definition\"\"\"\n",
    "    name: str\n",
    "    description: str\n",
    "    input_schema: Dict[str, Any]\n",
    "\n",
    "class MCPToolCall(BaseModel):\n",
    "    \"\"\"MCP tool invocation request\"\"\"\n",
    "    tool: str\n",
    "    arguments: Dict[str, Any]\n",
    "\n",
    "class MCPToolResult(BaseModel):\n",
    "    \"\"\"MCP tool invocation result\"\"\"\n",
    "    tool: str\n",
    "    result: Any\n",
    "    error: Optional[str] = None\n",
    "    execution_time_ms: float\n",
    "\n",
    "# Define available tools\n",
    "NETWORK_TOOLS = {\n",
    "    \"get_device_config\": {\n",
    "        \"name\": \"get_device_config\",\n",
    "        \"description\": \"Retrieve running configuration from a network device\",\n",
    "        \"input_schema\": {\n",
    "            \"type\": \"object\",\n",
    "            \"properties\": {\n",
    "                \"device_ip\": {\"type\": \"string\", \"description\": \"IP address of the device\"},\n",
    "                \"config_type\": {\"type\": \"string\", \"enum\": [\"running\", \"startup\"]}\n",
    "            },\n",
    "            \"required\": [\"device_ip\"]\n",
    "        }\n",
    "    },\n",
    "    \"check_interface_status\": {\n",
    "        \"name\": \"check_interface_status\",\n",
    "        \"description\": \"Check status of network interfaces on a device\",\n",
    "        \"input_schema\": {\n",
    "            \"type\": \"object\",\n",
    "            \"properties\": {\n",
    "                \"device_ip\": {\"type\": \"string\", \"description\": \"IP address of the device\"},\n",
    "                \"interface_name\": {\"type\": \"string\", \"description\": \"Specific interface (optional)\"}\n",
    "            },\n",
    "            \"required\": [\"device_ip\"]\n",
    "        }\n",
    "    }\n",
    "}\n",
    "\n",
    "async def execute_tool(tool_name: str, arguments: Dict[str, Any]) -> Any:\n",
    "    \"\"\"Execute a tool with given arguments (simulated)\"\"\"\n",
    "    if tool_name == \"get_device_config\":\n",
    "        device_ip = arguments[\"device_ip\"]\n",
    "        config_type = arguments.get(\"config_type\", \"running\")\n",
    "        return {\n",
    "            \"device\": device_ip,\n",
    "            \"config_type\": config_type,\n",
    "            \"config\": f\"!\\n! Configuration for {device_ip}\\n!\\nversion 15.2\\nhostname Router1\\n...\",\n",
    "            \"lines\": 247,\n",
    "            \"retrieved_at\": datetime.now().isoformat()\n",
    "        }\n",
    "    elif tool_name == \"check_interface_status\":\n",
    "        device_ip = arguments[\"device_ip\"]\n",
    "        interface_name = arguments.get(\"interface_name\")\n",
    "        if interface_name:\n",
    "            return {\n",
    "                \"device\": device_ip,\n",
    "                \"interface\": interface_name,\n",
    "                \"status\": \"up\",\n",
    "                \"protocol\": \"up\",\n",
    "                \"ip_address\": \"192.168.1.1\"\n",
    "            }\n",
    "        else:\n",
    "            return {\n",
    "                \"device\": device_ip,\n",
    "                \"interfaces\": [\n",
    "                    {\"name\": \"GigabitEthernet0/0\", \"status\": \"up\", \"protocol\": \"up\"},\n",
    "                    {\"name\": \"GigabitEthernet0/1\", \"status\": \"down\", \"protocol\": \"down\"}\n",
    "                ]\n",
    "            }\n",
    "    else:\n",
    "        raise ValueError(f\"Unknown tool: {tool_name}\")\n",
    "\n",
    "@app.get(\"/mcp/tools\", response_model=List[MCPTool])\n",
    "async def list_tools():\n",
    "    \"\"\"List all available tools\"\"\"\n",
    "    return [\n",
    "        MCPTool(\n",
    "            name=tool_data[\"name\"],\n",
    "            description=tool_data[\"description\"],\n",
    "            input_schema=tool_data[\"input_schema\"]\n",
    "        )\n",
    "        for tool_data in NETWORK_TOOLS.values()\n",
    "    ]\n",
    "\n",
    "@app.post(\"/mcp/call-tool\", response_model=MCPToolResult)\n",
    "async def call_tool(request: MCPToolCall):\n",
    "    \"\"\"Execute a tool\"\"\"\n",
    "    start_time = time.time()\n",
    "    \n",
    "    if request.tool not in NETWORK_TOOLS:\n",
    "        return MCPToolResult(\n",
    "            tool=request.tool,\n",
    "            result=None,\n",
    "            error=f\"Tool not found: {request.tool}\",\n",
    "            execution_time_ms=0\n",
    "        )\n",
    "    \n",
    "    try:\n",
    "        result = await execute_tool(request.tool, request.arguments)\n",
    "        execution_time = (time.time() - start_time) * 1000\n",
    "        \n",
    "        return MCPToolResult(\n",
    "            tool=request.tool,\n",
    "            result=result,\n",
    "            error=None,\n",
    "            execution_time_ms=execution_time\n",
    "        )\n",
    "    except Exception as e:\n",
    "        execution_time = (time.time() - start_time) * 1000\n",
    "        return MCPToolResult(\n",
    "            tool=request.tool,\n",
    "            result=None,\n",
    "            error=str(e),\n",
    "            execution_time_ms=execution_time\n",
    "        )\n",
    "\n",
    "# Test MCP server\n",
    "print(\"MCP Tools Available:\")\n",
    "tools = await list_tools()\n",
    "for tool in tools:\n",
    "    print(f\"  - {tool.name}: {tool.description}\")\n",
    "\n",
    "print(\"\\nTesting tool call:\")\n",
    "test_call = MCPToolCall(\n",
    "    tool=\"check_interface_status\",\n",
    "    arguments={\"device_ip\": \"192.168.1.1\"}\n",
    ")\n",
    "result = await call_tool(test_call)\n",
    "print(f\"  Tool: {result.tool}\")\n",
    "print(f\"  Execution time: {result.execution_time_ms:.2f}ms\")\n",
    "print(f\"  Result: {result.result}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example 3: AI Agent with MCP Integration\n",
    "\n",
    "Connect Claude to MCP server for autonomous network operations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from anthropic import Anthropic\n",
    "import json\n",
    "\n",
    "# Initialize Anthropic client\n",
    "client = Anthropic(api_key=os.environ.get(\"ANTHROPIC_API_KEY\"))\n",
    "\n",
    "# Define tools for Claude\n",
    "CLAUDE_TOOLS = [\n",
    "    {\n",
    "        \"name\": \"check_interface_status\",\n",
    "        \"description\": \"Check the operational status of network interfaces. Shows interface state, protocol status, and IP configuration.\",\n",
    "        \"input_schema\": {\n",
    "            \"type\": \"object\",\n",
    "            \"properties\": {\n",
    "                \"device_ip\": {\"type\": \"string\", \"description\": \"IP address of the device\"},\n",
    "                \"interface_name\": {\"type\": \"string\", \"description\": \"Specific interface (optional)\"}\n",
    "            },\n",
    "            \"required\": [\"device_ip\"]\n",
    "        }\n",
    "    },\n",
    "    {\n",
    "        \"name\": \"get_device_config\",\n",
    "        \"description\": \"Retrieve running or startup configuration from a network device.\",\n",
    "        \"input_schema\": {\n",
    "            \"type\": \"object\",\n",
    "            \"properties\": {\n",
    "                \"device_ip\": {\"type\": \"string\", \"description\": \"IP address of the device\"},\n",
    "                \"config_type\": {\"type\": \"string\", \"enum\": [\"running\", \"startup\"]}\n",
    "            },\n",
    "            \"required\": [\"device_ip\"]\n",
    "        }\n",
    "    }\n",
    "]\n",
    "\n",
    "async def execute_mcp_tool(tool_name: str, arguments: Dict[str, Any]) -> Dict[str, Any]:\n",
    "    \"\"\"Execute tool via MCP server (simulated)\"\"\"\n",
    "    # In production, this would make HTTP request to MCP server\n",
    "    return await execute_tool(tool_name, arguments)\n",
    "\n",
    "async def agent_query(prompt: str, device_ip: str, max_iterations: int = 5) -> Dict[str, Any]:\n",
    "    \"\"\"Execute AI agent query with tool calling\"\"\"\n",
    "    messages = [\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": f\"Device IP: {device_ip}\\n\\nQuery: {prompt}\"\n",
    "        }\n",
    "    ]\n",
    "    \n",
    "    tool_calls = []\n",
    "    iterations = 0\n",
    "    \n",
    "    while iterations < max_iterations:\n",
    "        iterations += 1\n",
    "        \n",
    "        # Call Claude with tools\n",
    "        response = client.messages.create(\n",
    "            model=\"claude-sonnet-4-5-20250929\",\n",
    "            max_tokens=2048,\n",
    "            tools=CLAUDE_TOOLS,\n",
    "            messages=messages\n",
    "        )\n",
    "        \n",
    "        # Check if Claude wants to use tools\n",
    "        if response.stop_reason == \"tool_use\":\n",
    "            assistant_content = []\n",
    "            \n",
    "            for content_block in response.content:\n",
    "                if content_block.type == \"tool_use\":\n",
    "                    tool_name = content_block.name\n",
    "                    tool_input = content_block.input\n",
    "                    tool_use_id = content_block.id\n",
    "                    \n",
    "                    # Execute the tool\n",
    "                    tool_result = await execute_mcp_tool(tool_name, tool_input)\n",
    "                    \n",
    "                    tool_calls.append({\n",
    "                        \"tool\": tool_name,\n",
    "                        \"input\": tool_input,\n",
    "                        \"result\": tool_result\n",
    "                    })\n",
    "                    \n",
    "                    assistant_content.append(content_block)\n",
    "                    \n",
    "                    # Add tool result to conversation\n",
    "                    messages.append({\"role\": \"assistant\", \"content\": assistant_content})\n",
    "                    messages.append({\n",
    "                        \"role\": \"user\",\n",
    "                        \"content\": [{\n",
    "                            \"type\": \"tool_result\",\n",
    "                            \"tool_use_id\": tool_use_id,\n",
    "                            \"content\": json.dumps(tool_result)\n",
    "                        }]\n",
    "                    })\n",
    "                else:\n",
    "                    assistant_content.append(content_block)\n",
    "        else:\n",
    "            # Claude provided final answer\n",
    "            final_response = \"\"\n",
    "            for content_block in response.content:\n",
    "                if hasattr(content_block, \"text\"):\n",
    "                    final_response += content_block.text\n",
    "            \n",
    "            return {\n",
    "                \"prompt\": prompt,\n",
    "                \"response\": final_response,\n",
    "                \"tool_calls\": tool_calls,\n",
    "                \"iterations\": iterations\n",
    "            }\n",
    "    \n",
    "    return {\n",
    "        \"prompt\": prompt,\n",
    "        \"response\": \"Maximum iterations reached\",\n",
    "        \"tool_calls\": tool_calls,\n",
    "        \"iterations\": iterations\n",
    "    }\n",
    "\n",
    "# Test AI agent\n",
    "print(\"Testing AI Agent with MCP Tools\\n\")\n",
    "result = await agent_query(\n",
    "    prompt=\"Check the interface status on this device\",\n",
    "    device_ip=\"192.168.1.1\"\n",
    ")\n",
    "\n",
    "print(f\"Prompt: {result['prompt']}\")\n",
    "print(f\"\\nResponse: {result['response']}\")\n",
    "print(f\"\\nTool Calls: {len(result['tool_calls'])}\")\n",
    "for i, call in enumerate(result['tool_calls'], 1):\n",
    "    print(f\"  {i}. {call['tool']}: {call['input']}\")\n",
    "print(f\"\\nIterations: {result['iterations']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example 4: Production Server with Monitoring\n",
    "\n",
    "Complete production server with health checks and metrics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from fastapi import FastAPI, Request\n",
    "from fastapi.middleware.cors import CORSMiddleware\n",
    "from datetime import datetime\n",
    "import psutil\n",
    "import time\n",
    "\n",
    "app = FastAPI(\n",
    "    title=\"Production Network AI API\",\n",
    "    description=\"Production-ready API with monitoring\",\n",
    "    version=\"1.0.0\"\n",
    ")\n",
    "\n",
    "# Middleware\n",
    "app.add_middleware(\n",
    "    CORSMiddleware,\n",
    "    allow_origins=[\"*\"],\n",
    "    allow_credentials=True,\n",
    "    allow_methods=[\"*\"],\n",
    "    allow_headers=[\"*\"],\n",
    ")\n",
    "\n",
    "# Global state\n",
    "START_TIME = datetime.now()\n",
    "REQUEST_COUNT = 0\n",
    "\n",
    "@app.middleware(\"http\")\n",
    "async def log_requests(request: Request, call_next):\n",
    "    \"\"\"Log all requests with timing\"\"\"\n",
    "    global REQUEST_COUNT\n",
    "    REQUEST_COUNT += 1\n",
    "    \n",
    "    start_time = time.time()\n",
    "    response = await call_next(request)\n",
    "    duration = (time.time() - start_time) * 1000\n",
    "    \n",
    "    print(f\"Request {REQUEST_COUNT}: {request.method} {request.url.path} - {duration:.2f}ms\")\n",
    "    return response\n",
    "\n",
    "@app.get(\"/health\")\n",
    "async def health_check():\n",
    "    \"\"\"Basic health check\"\"\"\n",
    "    uptime = (datetime.now() - START_TIME).total_seconds()\n",
    "    return {\n",
    "        \"status\": \"healthy\",\n",
    "        \"uptime_seconds\": uptime,\n",
    "        \"version\": \"1.0.0\",\n",
    "        \"timestamp\": datetime.now().isoformat()\n",
    "    }\n",
    "\n",
    "@app.get(\"/health/detailed\")\n",
    "async def detailed_health():\n",
    "    \"\"\"Detailed health check with system metrics\"\"\"\n",
    "    uptime = (datetime.now() - START_TIME).total_seconds()\n",
    "    \n",
    "    return {\n",
    "        \"status\": \"healthy\",\n",
    "        \"uptime_seconds\": uptime,\n",
    "        \"version\": \"1.0.0\",\n",
    "        \"timestamp\": datetime.now().isoformat(),\n",
    "        \"metrics\": {\n",
    "            \"cpu_percent\": psutil.cpu_percent(interval=0.1),\n",
    "            \"memory_percent\": psutil.virtual_memory().percent,\n",
    "            \"requests_handled\": REQUEST_COUNT\n",
    "        }\n",
    "    }\n",
    "\n",
    "@app.get(\"/metrics\")\n",
    "async def metrics():\n",
    "    \"\"\"Prometheus-style metrics\"\"\"\n",
    "    uptime = (datetime.now() - START_TIME).total_seconds()\n",
    "    \n",
    "    metrics_text = f\"\"\"# HELP service_uptime_seconds Service uptime\n",
    "# TYPE service_uptime_seconds gauge\n",
    "service_uptime_seconds {uptime}\n",
    "\n",
    "# HELP http_requests_total Total HTTP requests\n",
    "# TYPE http_requests_total counter\n",
    "http_requests_total {REQUEST_COUNT}\n",
    "\n",
    "# HELP system_cpu_percent CPU usage percentage\n",
    "# TYPE system_cpu_percent gauge\n",
    "system_cpu_percent {psutil.cpu_percent(interval=0.1)}\n",
    "\n",
    "# HELP system_memory_percent Memory usage percentage\n",
    "# TYPE system_memory_percent gauge\n",
    "system_memory_percent {psutil.virtual_memory().percent}\n",
    "\"\"\"\n",
    "    return metrics_text\n",
    "\n",
    "# Test the production server\n",
    "print(\"Production Server Status:\")\n",
    "health = await health_check()\n",
    "print(f\"  Status: {health['status']}\")\n",
    "print(f\"  Uptime: {health['uptime_seconds']:.1f}s\")\n",
    "\n",
    "print(\"\\nDetailed Health Check:\")\n",
    "detailed = await detailed_health()\n",
    "print(f\"  CPU: {detailed['metrics']['cpu_percent']:.1f}%\")\n",
    "print(f\"  Memory: {detailed['metrics']['memory_percent']:.1f}%\")\n",
    "print(f\"  Requests: {detailed['metrics']['requests_handled']}\")\n",
    "\n",
    "print(\"\\n✅ Production server configured successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Next Steps\n",
    "\n",
    "- Full code: [Chapter 38 on GitHub](https://github.com/eduardd76/AI_for_networking_and_security_engineers/tree/main/CODE/Volume-3-Production-Systems/Chapter-38-FastAPI-Server-MCP)\n",
    "- Learn more: [vExpertAI.com](https://vexpertai.com)\n",
    "- Author: Eduard Dulharu ([@eduardd76](https://github.com/eduardd76))\n",
    "\n",
    "**Production Deployment:**\n",
    "- Deploy with Docker: `docker build -t network-ai-api .`\n",
    "- Use Nginx for load balancing\n",
    "- Enable HTTPS with SSL certificates\n",
    "- Monitor with Prometheus + Grafana"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
