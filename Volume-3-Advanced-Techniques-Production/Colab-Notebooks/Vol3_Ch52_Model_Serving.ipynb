{
 "nbformat": 4,
 "nbformat_minor": 0,
 "metadata": {
  "colab": {
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Chapter 52: Model Serving Infrastructure\n",
    "Request batching and auto-scaling.\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "import random\n",
    "print(\"Model Serving ready\")\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "class Batcher:\n",
    "    def __init__(self,max_b=16): self.q=[]; self.max_b=max_b\n",
    "    def add(self,rid,tok): self.q.append({\"id\":rid,\"tok\":tok})\n",
    "    def get(self): batch=self.q[:self.max_b]; self.q=self.q[self.max_b:]; return batch\n",
    "    def infer(self,batch):\n",
    "        if not batch: return []\n",
    "        total_tok=sum(r[\"tok\"] for r in batch)\n",
    "        lat=10+total_tok*0.05+random.gauss(0,2)\n",
    "        return [{\"id\":r[\"id\"],\"lat_ms\":round(lat,1)} for r in batch]\n",
    "random.seed(42); b=Batcher(8)\n",
    "for i in range(32): b.add(\"req-\"+str(i),random.randint(100,500))\n",
    "all_r=[]\n",
    "while b.q: all_r.extend(b.infer(b.get()))\n",
    "print(\"Processed\",len(all_r),\"requests\")\n",
    "avg_lat=sum(r[\"lat_ms\"] for r in all_r)/len(all_r)\n",
    "print(\"Avg latency:\",round(avg_lat,1),\"ms\")\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "print(\"Batch | Latency(ms) | Req/s | GPU%\")\n",
    "print(\"-\"*40)\n",
    "for bs in [1,2,4,8,16,32]:\n",
    "    lat=15.0+bs*0.8; thr=bs/(lat/1000); gpu=min(0.95,bs/32)\n",
    "    print(str(bs)+\" | \"+str(round(lat,1))+\" | \"+str(round(thr,1))+\" | \"+str(round(gpu*100,0))+\"%\")\n",
    "class AutoScaler:\n",
    "    def __init__(self,mn=1,mx=10,tgt=100): self.r=mn; self.mn=mn; self.mx=mx; self.t=tgt\n",
    "    def scale(self,qps):\n",
    "        d=max(self.mn,min(self.mx,round(qps/self.t+0.5)))\n",
    "        a=\"up\" if d>self.r else \"down\" if d<self.r else \"none\"\n",
    "        self.r=d; return {\"replicas\":self.r,\"action\":a}\n",
    "as_=AutoScaler(2,8,50)\n",
    "for qps in [20,60,120,200,80,30]:\n",
    "    r=as_.scale(qps); print(\"QPS=\"+str(qps)+\" -> replicas=\"+str(r[\"replicas\"])+\" (\"+r[\"action\"]+\")\")\n"
   ],
   "outputs": [],
   "execution_count": null
  }
 ]
}