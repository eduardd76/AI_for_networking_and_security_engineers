{
 "nbformat": 4,
 "nbformat_minor": 0,
 "metadata": {
  "colab": {
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Chapter 23: Log Collection and Processing\n",
    "Centralized log collection, parsing, normalization, and enrichment.\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "import random, json\n",
    "from datetime import datetime, timedelta\n",
    "random.seed(42)\n",
    "print(\"Log Collection ready\")\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "base=datetime(2024,1,15,0,0,0)\n",
    "raw_logs=[{\"timestamp\":(base+timedelta(seconds=i*random.randint(1,60))).isoformat(),\"source\":random.choice([\"firewall\",\"webserver\",\"auth\",\"dns\"]),\"raw\":\"level=\"+random.choice([\"INFO\",\"WARN\",\"ERROR\"])+\" msg=event_\"+str(i)} for i in range(50)]\n",
    "print(\"Raw logs collected:\",len(raw_logs))\n",
    "by_source={}\n",
    "for l in raw_logs: by_source[l[\"source\"]]=by_source.get(l[\"source\"],0)+1\n",
    "for src,cnt in sorted(by_source.items()): print(\" \"+src+\":\",cnt)\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "def parse_log(raw):\n",
    "    parts={p.split(\"=\")[0]:p.split(\"=\")[1] for p in raw[\"raw\"].split() if \"=\" in p}\n",
    "    return {**raw,**parts}\n",
    "parsed=[parse_log(l) for l in raw_logs]\n",
    "errors=[p for p in parsed if p.get(\"level\")==\"ERROR\"]\n",
    "print(\"Parsed:\",len(parsed),\"Errors:\",len(errors))\n",
    "print(\"Sample:\",json.dumps(parsed[0],indent=2)[:200])\n"
   ],
   "outputs": [],
   "execution_count": null
  }
 ]
}