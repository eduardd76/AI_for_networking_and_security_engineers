{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyLangChainTheory"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python",
      "version": "3.11.0"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "intro"
      },
      "source": [
        "# Chapter 16: LangChain for Network Operations\n",
        "\n",
        "## A Conceptual Guide for Network Engineers\n",
        "\n",
        "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/eduardd76/AI_for_networking_and_security_engineers/blob/master/Volume-2-Practical-Applications/Colab-Notebooks/Vol2_Ch16_LangChain_Theory.ipynb)\n",
        "\n",
        "### What This Notebook Is About\n",
        "\n",
        "This is **NOT** a coding tutorial.\n",
        "\n",
        "This is a **conceptual guide** to understanding LangChain through networking analogies.\n",
        "\n",
        "By the end, you'll understand:\n",
        "- What LangChain is and why it exists\n",
        "- How its components work\n",
        "- When to use it vs write code yourself\n",
        "- How it fits with Chapters 13, 14, 15\n",
        "\n",
        "### Read the Chapter First\n",
        "\n",
        "Before running code, read **Chapter 16: LangChain for Network Operations** in the book.\n",
        "\n",
        "This notebook reinforces those concepts with minimal working examples.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "problem"
      },
      "source": [
        "## Part 1: The Problem LangChain Solves\n",
        "\n",
        "### The Boilerplate Problem\n",
        "\n",
        "When you build AI systems, you write the same patterns over and over:\n",
        "\n",
        "**Pattern 1: Prompting**\n",
        "```\n",
        "Every AI call:\n",
        "1. Build prompt\n",
        "2. Add context\n",
        "3. Format for API\n",
        "4. Send to LLM\n",
        "```\n",
        "\n",
        "**Pattern 2: Parsing**\n",
        "```\n",
        "Every response:\n",
        "1. Extract text\n",
        "2. Check if JSON\n",
        "3. Validate structure\n",
        "4. Handle errors\n",
        "```\n",
        "\n",
        "**Pattern 3: Memory**\n",
        "```\n",
        "Every conversation:\n",
        "1. Store messages\n",
        "2. Track history\n",
        "3. Manage size\n",
        "4. Retrieve context\n",
        "```\n",
        "\n",
        "**The Result**: You write 200+ lines of boilerplate code for each system.\n",
        "\n",
        "### The LangChain Solution\n",
        "\n",
        "**LangChain provides pre-built components for these patterns.**\n",
        "\n",
        "Instead of:\n",
        "```python\n",
        "# Write this for every system (200 lines)\n",
        "prompt = f\"Analyze: {config}\"\n",
        "response = call_api(prompt)\n",
        "data = parse_json(response)\n",
        "memory.store(data)\n",
        "# ... 150 more lines ...\n",
        "```\n",
        "\n",
        "Use:\n",
        "```python\n",
        "# Write once (5 lines)\n",
        "chain = prompt | llm | parser\n",
        "result = chain.invoke({\"config\": config})\n",
        "```\n",
        "\n",
        "**The principle**: Don't repeat infrastructure work. Use building blocks.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "concepts"
      },
      "source": [
        "## Part 2: Core Concepts with Networking Analogies\n",
        "\n",
        "### Concept 1: Prompts = Configuration Templates\n",
        "\n",
        "**Problem**: Hard-coded prompts in code\n",
        "```python\n",
        "prompt = f\"Analyze {device} for security issues\"\n",
        "# If you change the prompt, rewrite code\n",
        "```\n",
        "\n",
        "**Solution**: Prompt templates\n",
        "```\n",
        "Template: \"Analyze {device} for {issue_type} issues\"\n",
        "Use anywhere: Just fill in variables\n",
        "Change anytime: No code changes needed\n",
        "```\n",
        "\n",
        "**Networking analogy**: Device config templates\n",
        "- Hard way: Configure each router individually\n",
        "- Smart way: Create template, apply to all routers\n",
        "- Change template, all routers update\n",
        "\n",
        "---\n",
        "\n",
        "### Concept 2: LLMs = Interchangeable Backends\n",
        "\n",
        "**Problem**: Code specific to one AI model\n",
        "```python\n",
        "response = claude_api.call(prompt)  # Hard-coded to Claude\n",
        "# Want to use OpenAI? Rewrite everything\n",
        "```\n",
        "\n",
        "**Solution**: LLM abstraction layer\n",
        "```\n",
        "llm = ChatAnthropic()  # Or ChatOpenAI or ChatOlLama\n",
        "response = llm.invoke(prompt)  # Works with any\n",
        "# Change to OpenAI? Change one line\n",
        "```\n",
        "\n",
        "**Networking analogy**: Routing protocol abstraction\n",
        "- Hard way: Code specific to BGP\n",
        "- Smart way: Abstraction layer for any routing protocol\n",
        "- Switching BGP → OSPF? Configuration change, not code rewrite\n",
        "\n",
        "---\n",
        "\n",
        "### Concept 3: Parsers = Output Validation\n",
        "\n",
        "**Problem**: AI returns text, code needs data\n",
        "```\n",
        "AI: \"The config has 3 critical issues: weak password, no encryption...\"\n",
        "Your code: Now I need to parse this text somehow...\n",
        "```\n",
        "\n",
        "**Solution**: Parser converts text → structured data\n",
        "```json\n",
        "{\n",
        "  \"issues\": [\n",
        "    {\"severity\": \"critical\", \"type\": \"weak_password\"},\n",
        "    {\"severity\": \"critical\", \"type\": \"no_encryption\"}\n",
        "  ]\n",
        "}\n",
        "```\n",
        "\n",
        "**Networking analogy**: Config parsing\n",
        "```\n",
        "show command output: Plain text\n",
        "Parser: Converts to structured data\n",
        "Your code: Accesses data.interface[0].status\n",
        "```\n",
        "\n",
        "---\n",
        "\n",
        "### Concept 4: Chains = Workflow Sequences\n",
        "\n",
        "**Problem**: Multi-step processes are complex\n",
        "```python\n",
        "# Manual plumbing between steps\n",
        "prompt_output = prompt.format(data)\n",
        "llm_output = llm.invoke(prompt_output)\n",
        "parser_output = parser.parse(llm_output)\n",
        "# Each step is separate, error handling painful\n",
        "```\n",
        "\n",
        "**Solution**: Chain automatically connects steps\n",
        "```python\n",
        "# Automatic plumbing\n",
        "chain = prompt | llm | parser\n",
        "result = chain.invoke(data)\n",
        "# Each step feeds to next, error handling built-in\n",
        "```\n",
        "\n",
        "**Networking analogy**: Service chain in SD-WAN\n",
        "```\n",
        "Manual: Firewall → packet → DPI → packet → route\n",
        "SD-WAN: Service chain (automatic plumbing)\n",
        "```\n",
        "\n",
        "---\n",
        "\n",
        "### Concept 5: Memory = Operational State\n",
        "\n",
        "**Problem**: Each AI call has no context\n",
        "```\n",
        "Q1: \"What's our BGP AS?\" → \"65001\"\n",
        "Q2: \"What about redundancy?\" → (doesn't know about Q1)\n",
        "```\n",
        "\n",
        "**Solution**: Memory tracks conversation\n",
        "```\n",
        "Q1: \"What's our BGP AS?\" → \"65001\" (stored)\n",
        "Q2: \"What about redundancy?\" → References Q1 answer\n",
        "```\n",
        "\n",
        "**Networking analogy**: Device state\n",
        "```\n",
        "Single lookup: show ip route 10.0.0.0\n",
        "Ongoing operation: Device maintains routing table (memory)\n",
        "```\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "runnable"
      },
      "source": [
        "## Part 3: The Fundamental Principle - Runnables\n",
        "\n",
        "### The Core Insight\n",
        "\n",
        "**Everything in LangChain is a \"Runnable\"**\n",
        "\n",
        "What's a Runnable?\n",
        "```\n",
        "A Runnable is anything with:\n",
        "- An .invoke() method (call it with data)\n",
        "- Returns output\n",
        "- Can be piped with other Runnables\n",
        "```\n",
        "\n",
        "**Examples of Runnables:**\n",
        "- Prompt (formats input)\n",
        "- LLM (calls AI model)\n",
        "- Parser (structures output)\n",
        "- Tool (calls external system)\n",
        "- Any function you write\n",
        "\n",
        "### Why This Matters\n",
        "\n",
        "**Because everything is Runnable, everything can be piped together.**\n",
        "\n",
        "```python\n",
        "# Simple pipe (sequential)\n",
        "chain = prompt | llm | parser\n",
        "\n",
        "# Complex pipe (with branches)\n",
        "chain = categorize_llm | (if_security_llm | if_routing_llm) | results\n",
        "\n",
        "# Parallel pipes\n",
        "chain = input_llm | [security_llm, performance_llm, compliance_llm] | aggregator\n",
        "```\n",
        "\n",
        "**The principle**: Compose small pieces into complex systems.\n",
        "\n",
        "This is exactly how networks work:\n",
        "- BGP → Redistributes to OSPF → Redistributes to clients\n",
        "- Each component takes input, produces output\n",
        "- Each can be tested independently\n",
        "- Each can be upgraded without touching others\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "setup"
      },
      "source": [
        "## Part 4: Hands-On Demonstration\n",
        "\n",
        "Now let's see these concepts in action with minimal code.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "install"
      },
      "outputs": [],
      "source": [
        "# Install LangChain\n",
        "!pip install -q langchain langchain-anthropic\n",
        "\n",
        "import os\n",
        "from getpass import getpass\n",
        "\n",
        "# Get API key\n",
        "if 'ANTHROPIC_API_KEY' not in os.environ:\n",
        "    api_key = getpass('Enter your Anthropic API key: ')\n",
        "    os.environ['ANTHROPIC_API_KEY'] = api_key\n",
        "\n",
        "print('✅ LangChain installed and API key configured')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "demo_prompt"
      },
      "source": [
        "### Demo 1: Prompts (Templates)\n",
        "\n",
        "Let's see how prompt templates work.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "prompt_example"
      },
      "outputs": [],
      "source": [
        "from langchain_core.prompts import ChatPromptTemplate\n",
        "\n",
        "# Define template once\n",
        "prompt_template = ChatPromptTemplate.from_template(\n",
        "    \"Analyze this {device_type} config for {issue_type} issues:\\n\\n{config}\"\n",
        ")\n",
        "\n",
        "# Use the template multiple ways\n",
        "# Use case 1: Cisco, security issues\n",
        "prompt1 = prompt_template.format(\n",
        "    device_type=\"Cisco IOS\",\n",
        "    issue_type=\"security\",\n",
        "    config=\"interface Gi0/1\\n ip address 10.1.1.1 255.255.255.0\\n\"\n",
        ")\n",
        "\n",
        "print(\"Prompt 1 (Cisco security):\")\n",
        "print(prompt1)\n",
        "print()\n",
        "\n",
        "# Use case 2: Juniper, performance issues\n",
        "prompt2 = prompt_template.format(\n",
        "    device_type=\"Juniper Junos\",\n",
        "    issue_type=\"performance\",\n",
        "    config=\"interfaces { ge-0/0/1 { unit 0 { family inet { address 10.1.1.1/24 } } } }\"\n",
        ")\n",
        "\n",
        "print(\"Prompt 2 (Juniper performance):\")\n",
        "print(prompt2)\n",
        "print()\n",
        "\n",
        "print(\"Key insight: Same template, different uses. No code changes needed.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "demo_llm"
      },
      "source": [
        "### Demo 2: LLMs (Abstraction Layer)\n",
        "\n",
        "All LLMs work the same way in LangChain.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "llm_example"
      },
      "outputs": [],
      "source": [
        "from langchain_anthropic import ChatAnthropic\n",
        "\n",
        "# Create an LLM (same interface for Claude, OpenAI, etc)\n",
        "llm = ChatAnthropic(\n",
        "    model=\"claude-3-5-sonnet-20241022\",\n",
        "    max_tokens=300,\n",
        "    temperature=0  # Deterministic for analysis\n",
        ")\n",
        "\n",
        "# Use it\n",
        "response = llm.invoke(\"What is BGP in networking?\")\n",
        "\n",
        "print(\"LLM Response:\")\n",
        "print(response.content)\n",
        "print()\n",
        "print(\"Key insight: If you wanted OpenAI instead, change 'ChatAnthropic' to 'ChatOpenAI'.\")\n",
        "print(\"The rest of your code stays the same.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "demo_chain"
      },
      "source": [
        "### Demo 3: Chains (Composing Components)\n",
        "\n",
        "This is where LangChain shows its power: composing components.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "chain_example"
      },
      "outputs": [],
      "source": [
        "# Create components\n",
        "prompt = ChatPromptTemplate.from_template(\n",
        "    \"Explain this network concept in one sentence: {concept}\"\n",
        ")\n",
        "\n",
        "llm = ChatAnthropic(model=\"claude-3-5-sonnet-20241022\", max_tokens=100, temperature=0)\n",
        "\n",
        "# Compose into a chain using the | (pipe) operator\n",
        "chain = prompt | llm\n",
        "\n",
        "print(\"Chain Architecture:\")\n",
        "print(\"[User Input] → [Prompt] → [LLM] → [Response]\")\n",
        "print()\n",
        "\n",
        "# Use the chain\n",
        "result = chain.invoke({\"concept\": \"OSPF\"})\n",
        "\n",
        "print(\"Input: 'OSPF'\")\n",
        "print()\n",
        "print(\"Output:\")\n",
        "print(result.content)\n",
        "print()\n",
        "print(\"Key insight: The chain handles all plumbing between components.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "demo_memory"
      },
      "source": [
        "### Demo 4: Memory (Conversation Context)\n",
        "\n",
        "Memory lets conversations maintain context across turns.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "memory_example"
      },
      "outputs": [],
      "source": [
        "from langchain.memory import ConversationBufferMemory\n",
        "\n",
        "# Create memory\n",
        "memory = ConversationBufferMemory()\n",
        "\n",
        "# First message\n",
        "memory.save_context(\n",
        "    {\"input\": \"What's our BGP AS number?\"},\n",
        "    {\"output\": \"Our BGP AS is 65001\"}\n",
        ")\n",
        "\n",
        "print(\"After first exchange:\")\n",
        "print(\"Q: What's our BGP AS number?\")\n",
        "print(\"A: Our BGP AS is 65001\")\n",
        "print()\n",
        "\n",
        "# Second message (has context from first)\n",
        "memory.save_context(\n",
        "    {\"input\": \"What about redundancy?\"},\n",
        "    {\"output\": \"For BGP AS 65001, redundancy means dual BGP sessions...\"}\n",
        ")\n",
        "\n",
        "print(\"After second exchange:\")\n",
        "print(\"Q: What about redundancy?\")\n",
        "print(\"A: For BGP AS 65001, redundancy means...\")\n",
        "print()\n",
        "print(\"Key insight: Memory creates continuity. The second answer references the first.\")\n",
        "print(\"Without memory, the second question wouldn't know about the AS number.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "architecture"
      },
      "source": [
        "## Part 5: The Big Picture - Integration\n",
        "\n",
        "### How It All Fits Together\n",
        "\n",
        "```\n",
        "Documentation (Ch13)\n",
        "    ↓ (generated automatically)\n",
        "Searchable Index (Ch14: RAG)\n",
        "    ↓ (can answer questions)\n",
        "LangChain Components (Ch16)\n",
        "    ├─ Prompts\n",
        "    ├─ LLMs\n",
        "    ├─ Parsers\n",
        "    ├─ Memory\n",
        "    └─ Tools (including RAG)\n",
        "    ↓ (chains these together)\n",
        "Agents (Ch15: Autonomous systems)\n",
        "    ├─ Observe (use tools)\n",
        "    ├─ Think (use LLM)\n",
        "    ├─ Act (use tools)\n",
        "    └─ Verify (use tools)\n",
        "    ↓ (produces results)\n",
        "Autonomous Network Operations\n",
        "```\n",
        "\n",
        "### Why This Architecture Works\n",
        "\n",
        "**Separation of Concerns**:\n",
        "- Ch13: Generate accurate documentation\n",
        "- Ch14: Make documentation searchable\n",
        "- Ch16: Orchestrate components\n",
        "- Ch15: Make autonomous decisions\n",
        "\n",
        "**Each layer uses the previous**:\n",
        "- Agents use LangChain components\n",
        "- LangChain components use RAG\n",
        "- RAG searches documentation\n",
        "- Documentation is auto-generated\n",
        "\n",
        "**Result**: Clean, maintainable, extensible system\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "decision"
      },
      "source": [
        "## Part 6: Decision Tree - When to Use LangChain\n",
        "\n",
        "### Use LangChain When:\n",
        "\n",
        "1. **Multi-step workflows** (3+ steps)\n",
        "   - Example: Prompt → LLM → Parser\n",
        "   - Without: 50 lines of boilerplate\n",
        "   - With LangChain: 5 lines\n",
        "\n",
        "2. **Conversation memory** needed\n",
        "   - Example: Multi-turn diagnostics\n",
        "   - Without: 100 lines of memory management\n",
        "   - With LangChain: 10 lines\n",
        "\n",
        "3. **Tool integration** with agents\n",
        "   - Example: Agent calls tools to diagnose\n",
        "   - Without: Complex decision logic\n",
        "   - With LangChain: Agents built-in\n",
        "\n",
        "4. **Future flexibility** (might change LLM)\n",
        "   - Example: Start with Claude, maybe switch\n",
        "   - Without: Rewrite code if switching\n",
        "   - With LangChain: Change one line\n",
        "\n",
        "5. **Production systems**\n",
        "   - Error handling built-in\n",
        "   - Monitoring built-in\n",
        "   - Caching built-in\n",
        "\n",
        "### Don't Use LangChain When:\n",
        "\n",
        "1. **Single API call**\n",
        "   - Just call LLM directly (no overhead)\n",
        "\n",
        "2. **Ultra-low latency** critical\n",
        "   - LangChain adds small overhead\n",
        "\n",
        "3. **Fully scripted** workflow\n",
        "   - No decisions needed\n",
        "\n",
        "4. **Learning** how LLMs work\n",
        "   - Start with raw API, learn fundamentals first\n",
        "\n",
        "5. **Simple tools** (just call one function)\n",
        "   - Might be overkill\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "learn"
      },
      "source": [
        "## Part 7: Learning Path\n",
        "\n",
        "### How to Approach LangChain\n",
        "\n",
        "**Phase 1 (Week 1): Understand Components**\n",
        "- What is a prompt?\n",
        "- What is an LLM?\n",
        "- What is a parser?\n",
        "- (Conceptual understanding, no code)\n",
        "\n",
        "**Phase 2 (Week 2): Understand Composition**\n",
        "- How do components connect?\n",
        "- What is a chain?\n",
        "- What is the Runnable protocol?\n",
        "- (Building mental models)\n",
        "\n",
        "**Phase 3 (Week 3): Understand Patterns**\n",
        "- What is a conversation pattern?\n",
        "- What is an agent pattern?\n",
        "- What is a RAG pattern?\n",
        "- (Recognizing workflows)\n",
        "\n",
        "**Phase 4 (Week 4): Build Simple Systems**\n",
        "- Create a simple chain\n",
        "- Add conversation memory\n",
        "- Use with tools\n",
        "- (Hands-on practice)\n",
        "\n",
        "**Phase 5 (Week 5+): Build Production Systems**\n",
        "- Error handling\n",
        "- Monitoring\n",
        "- Optimization\n",
        "- (Advanced concerns)\n",
        "\n",
        "### Key Point\n",
        "\n",
        "**Concepts come BEFORE code.**\n",
        "\n",
        "Don't try to understand code without understanding the concepts.\n",
        "You're not learning Python syntax—you're learning engineering patterns.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "summary"
      },
      "source": [
        "## Summary: The Big Insight\n",
        "\n",
        "### Why LangChain Exists\n",
        "\n",
        "Network engineers understand this principle:\n",
        "\n",
        "**Don't repeat infrastructure work. Automate common patterns.**\n",
        "\n",
        "```\n",
        "Network Analogy:\n",
        "- Without automation: Configure each router individually (hours)\n",
        "- With Ansible: Define template, apply everywhere (minutes)\n",
        "\n",
        "AI Parallel:\n",
        "- Without LangChain: Write same code for each system (hours)\n",
        "- With LangChain: Define components, compose them (minutes)\n",
        "```\n",
        "\n",
        "### What You Now Understand\n",
        "\n",
        "✅ What LangChain is (engineering framework, not AI)\n",
        "✅ Why it exists (avoid repeating boilerplate)\n",
        "✅ How it works (components + composition)\n",
        "✅ When to use it (multi-step, memory, production)\n",
        "✅ How it integrates (with Ch13, 14, 15)\n",
        "\n",
        "### Next Steps\n",
        "\n",
        "1. **Read Chapter 16** in the book (theory)\n",
        "2. **Run this notebook** to see concepts in action\n",
        "3. **Build simple chains** (Phase 4 in learning path)\n",
        "4. **Integrate with agents** (combine with Ch15)\n",
        "5. **Deploy to production** (Phase 5)\n",
        "\n",
        "---\n",
        "\n",
        "**Remember**: You don't need to be an AI expert to use LangChain.\n",
        "\n",
        "You need to understand engineering principles.\n",
        "\n",
        "And you already know those from networking.\n"
      ]
    }
  ]
}
